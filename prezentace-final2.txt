Vytvoreni testovaci klastru

Samotny program algoritmu samozrejme nestaci.

Pro aplikaci algoritmu je nutne nejake prostredi, schopne provozovat aplikace urcene pro Apache Spark.

Pro tento projekt jsem zvolil platformu Apache Hadoop, protoze pro tuto paltformu je Spark primarne urcen.

Hadoop je open source platforma pro zpracovani velkych objemu dat.
Tato platforma je urcena pro pouziti v ramci rozsahlych klastru v prostredi data center.

Ackoliv je Hadoop implementovan v jayzce Java, 
Je urcen vzhradne pro operacni szstem linux a architekturu procesoru x86.

Jádro hadoopu obsahuje tøi základní komponenty.
Distribuovaný souborový systém HDFS, 
systém pro správu prostøedkù klastru YARN
a výpoèetní systém MapReduce.

Vyhledem k omezenzm prostredkum jsem postavil virtualni hadoop klastr na me lokalni pracovni stanici.

Klastr se skladal ze ètyø uzlu jednoho Masteru a tri Workeru.

Jako hypervizor jsem pouzil VitrualBOX od spoecnosti Oracle.

Jako distribuci linuxu jsem zvolil Centos 7.

U hadoopu podobne jako u Linuxu existuji specializovane distribuce uynadnujici instalaci, ja jsem zvolil distribuci HDP od spolecnosti HortonWorks  

Instalace hadoopu je komlexni zalezitost. Na vsechny uzly v ramci klatru je treba nainstalovat radu sluzeb a nakonfigurovat je k vzajemne soucinosti.

Vystupem teto faze projektu tedy byla funkcni hadoop instalace zahrnujici distribuopvane uloziste a behove prostredi pro Apache Spark.

