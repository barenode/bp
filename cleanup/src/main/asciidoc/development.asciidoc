
== Implementace vybranıch algoritmù v øešené oblasti

=== Vıbìr vhodnıch technologií

==== Vıbìr programovacího jazyka

Spark podporuje nìkolik rùznıch jazykù a to jsou Scala, Java, Python a R. Scala je jazyk, kterı se pokusil zkombinovat objektovì orientované a funkcionální programování. Scala je JMV jazyk, kterı potøebuje ke svému bìhu nainstalovanou Javu, konkrétnì její bìhové prostøedí. Scala je nativní jazyk Sparku a jeho pøidruenıch knihoven. Zdrojovı kód v jazyce Scala se pøi komilaci pøevede do Java byte kódu. To znamená, e se aplikace distribuuje ve formì javovskıch archivù takzvanıch jarù. Toto má za následek, e k vıvoji aplikací mùzeme pouít také pøímo Javu samotnou. Aplikace napsané v Javì mohou pouívat knihovny napsané ve Scale a naopak. Python je velice populární jazyk urèenı pro rychlé protypování. V posledních letech se stale vícemén standartem pro experimentování v oblasti umìlé inteligence a strojového uèení. Python má k dispozici mnoho specializovanæh knihoven jako jsou Sciki-learn nebo TensorFlow. Python není nativním jazykem Sparku, místo toho pouívá specializovanou knihovnu Py4J pro interakci s JVM. R je velice populární jazyk v rámci statistické komunity. 

Pro vıvoj aplikace byl vyhodnocen jako nejvhodnìjší jazyk Scala. Pøi vıvoji se budeme moci nechat inspirovat praktikami pouitımi pøi vıvoji Sparku samotného, zejména jeho knihoven urèenıch pro strojové uèení. Dále budeme pouívat Python k optimalizaci hyper parametrù jednotlivıch algoritmù. Python budeme pouívat interaktivnì v prostøedí takzvanıch zápisnikù.     

==== Vıbìr nástroje pro automatizaci buildù aplikace

Nástroj pro automatizaci buildù zaštíuje kompletní cyklus sestavení aplikace. Toto zahrnuje zejména kompilaci zdrojového kódu a spuštìní kompletní sady projektovıch testù. Na závìr cyklu nástroj vytvoøí koneènou verzi aplikace a uloí ji pod pøíslušnım identifikátorem verze do sdíleného repositáøe. Pro aplikace vyvıjené v jazyce Scala existují dva základní build nástroje. První sbt (Scala build tool) je orientován vıluènì na Scalu. Druhı, Apache Maven je obecnı nástroj pro vıvoj aplikací v Javì, kterı se stal víceménì standartem. Pro náš projekt byl vybrán nástroj Apache Maven. 

==== Vıbìr IDE

Vedle pro automatizaci buildù budeme dale potrebovat integrovane vyvojove prostredi . Takove prostredi usnadnuje psani zdrojoveho kodu spousteni jednotlivych testu atd. Na toto prostredi bylo nekolik zakladnich pozadavku ktere musi splnovat:

1) Podpora Pache Maven. IDE by melo byt schopne naimportovat informace s deskriptoru aplikace. Primarne se jedna o sadu zavislosti, ktera by mela byt nadefinovana na jedinem miste. Apache Maven je zahrnuta ve vetsine java IDE.

2) Podpora Scaly. Scala je jeden z monha JVM jazyku a je mnohem mene pouzivana nez Java samotna. Kvalitni pdpora toho jazyka nei uplne bezna.

2) Podpora Scala testu. Ackoliv je Apache Maven skvely nastroj a pri sestavovani aplikace spusti kompletni sadu testu, pri implementaci samotne potrebujeme jemnejsi kontrolu nad tim , ktery test spoustime. IDE by melo tuto moznost podporovat a umoznit nam spoustet dane testy jednotlive podle potreby. V nasem porojektu pouzijeme stejny testovaci ramec jako je pouzity ve Sparku samotnem. To proto aby jsme mohli pouzit stejen kontruktuy usnadnujici vytvareni a rusenich instanci SParku samotneho. 


Do uzsiho vyberu postoupili dva kandidati. Prvni je Scala IDE, vyvojove postredi postavene na popularni platforme Eclipse. Druhe je nemene popularni vyvojove prostredi IntelliJ IDEA. Scala IDE ve verzi 4.7.0 splnovalo prvni dva z nasich pozadavku. Nicmene se nepodarila uzpokojive zapojit podpora testu. IntelliJ IDEA splniula vsechny tri pozadavky na vybornou. Pro vyvoj nasi plaikce tedy pouzijeme toto IDE.


Zejména proto, e osahuje Tento je velice flexibilni a dobre zdokumentovany <https://maven.apache.org>. Vsechny projekty pro ktere je pouzity Apache Maven maji jednontnou adresarovou strukturu pro zdrojove kody a pridruzene soubory. Tato struktura je nasledujici:

---
src/
  main/
    resources/   
      <v adresari resources jsou soubory ktere se zahrnou do vysledneho baliku>
    scala/
      <zdrojove soubory aplikace>
  test
    resources/    
      <v adresari resources jsou soubory ktere se zahrnou do vysledneho baliku s testy>
    scala/
      <zdrojove soubory testu aplikace>

---

Dale projekty rizene Apache Maven obsahuji deskriptor projektu. Tento deskriptor je ulozeny v root projektu a ma fixni jemno pom.xml. Tento deskriptor obsahuje nekolik casti, ktere ovlivnuji vyslednou podobu aplikace. Nase aplikace bude obsahovat nasledujici casti:

---
  <groupId>org.barenode</groupId>
  <artifactId>ml-on-spark</artifactId>
  <version>1.0</version>  
  <type>jar</type>
  <name>Strojove ucemni na paltforme Spark</name>
---

Tato sekce obsahuje zakldani informace o projektu. Jemno, verzi a typ. 
Tyto inromace ovlivnuji jak bude cilova aplikace pojmenovana a jakeho bude type. V nasem pripade tesy vznikne java balik se jmenem ml-on-spark-1.0.jar.

---
  <properties>   
    <spark.version>2.4.4</spark.version>
    <java.version>1.8</java.version>    
    <scala.version>2.11.12</scala.version>
  </properties>
---

V sekci properties definujeme promenne pouzite dale v deskriptoru. V nasem pripade tyto promenne opbsahuji verze jednotlivych zavislosti projektu. Aktualni posledni vydana verze Sparku ma cislo 2.4.4, pouzijeme tedy stejne verze javy a scaly, ktere jsou pouzity tam. Pro tuto verzi sparku byla pouzita java 8 a scala 2.11.12.

---
  <dependencies>   
    <!-- scala -->
		<dependency>
      <groupId>org.scala-lang</groupId>
      <artifactId>scala-library</artifactId>
      <version>${scala.version}</version>
    </dependency>
    
    <!-- spark -->
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-core_${scala.binary.version}</artifactId>
      <version>${spark.version}</version>
		</dependency>
     
    ...
    
  <dependencies>    
---

Sekce dependencies obsahuje takzvane zavislosti projektu. Realne se jedna o knihovny (jary) na ktere se budemem odkazovat z nasich zdrojovych kodu. Apache Maven pro nas tyto knihvny automaticky stahne a nalinkuje vcetne tranzitivnich zavislosti techto knihoven. Seznam dependenci je rozsahny, uvadime zde tedy pouze zkracenou verzi s knihovnami pro spark a pro scalu.

Dale deskriptor obsahuje definici rozsireni pro scalu. Ve vychozim stavu podporuje Apache MAven pouze javu. Podpora scaly se musi expilictne definovat. Prvni rozsireni scala-maven-plugin aktivuje kompilaci scala zdrojovych souboru. Dalsi rozsireni scalatest-maven-plugin aktivuje podporu junit testu. Tato definice obsahuje dalsi atributy potrebne pro vytvareni lokalnich instanci Sparku pro potreby jednotlivych testu.

Sestaveni aplikace aktivujeme z prikazove radky prikazem:

---
mvn clean install
---

Na konzili se nam naslednbe vypisi informace o uspesnem zkompletovani aplikace:

---
---

V automaticky vytvorenem adresari target je ulozena vysledna aplikace. Tato je zatim prazdna jelikjoz nas projekt zatim nebsahuje zadny zdrojovy kody.