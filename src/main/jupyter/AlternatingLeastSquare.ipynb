{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "env: SPARK_HOME=/usr/hdp/current/spark2-client\n",
      "findspark initialized ...\n",
      "pyspark ready ...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%env SPARK_HOME=/usr/hdp/current/spark2-client\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "print('findspark initialized ...')\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr, col, column, max, min\n",
    "\n",
    "spark = SparkSession.builder.appName('mlonspark')\\\n",
    "    .config('spark.executor.instances', '6')\\\n",
    "    .config('spark.jars', '/opt/dev/target/ml-on-spark-1.0.jar')\\\n",
    "    .getOrCreate()\n",
    "\n",
    "#   \n",
    "    \n",
    "print('pyspark ready ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User-ID: string (nullable = true)\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- Book-Rating: string (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- bookId: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = spark.read.format(\"parquet\").load(\"/data/books/ratings-train.parquet\")\n",
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlternatingLeastSquare_4fc384839c675b4b1dd9\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from mlonspark.alternating_least_square import AlternatingLeastSquare\n",
    "from pyspark.ml.recommendation import ALS\n",
    "#from mlonspark.alternating_least_square import XALS\n",
    "\n",
    "als = AlternatingLeastSquare()\\\n",
    "    .setUserCol(\"userId\")\\\n",
    "    .setItemCol(\"bookId\")\\\n",
    "    .setRatingCol(\"rating\")\\\n",
    "    .setMaxIter(10)\n",
    "\n",
    "#\\\n",
    "#    .setImplicitPrefs(True)\n",
    "\n",
    "print(als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlternatingLeastSquare_4fc384839c675b4b1dd9\n"
     ]
    }
   ],
   "source": [
    "model = als.fit(train)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write().overwrite().save('/data/books/model.alsmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "#from mlonspark.alternating_least_square import AlternatingLeastSquareModel\n",
    "\n",
    "#model = AlternatingLeastSquareModel.read().load('/data/books/model.alsmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlternatingLeastSquare_4fc384839c675b4b1dd9\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User-ID: string (nullable = true)\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- Book-Rating: string (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- bookId: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = spark.read.format(\"parquet\").load(\"/data/books/ratings-test.parquet\")\n",
    "test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User-ID: string (nullable = true)\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- Book-Rating: string (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- bookId: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- prediction: float (nullable = false)\n",
      "\n",
      "+-------+----------+-----------+------+------+--------------------+----+------+-----------+\n",
      "|User-ID|      ISBN|Book-Rating|rating|bookId|            Location| Age|userId| prediction|\n",
      "+-------+----------+-----------+------+------+--------------------+----+------+-----------+\n",
      "| 127429|0380778556|          0|   1.0|   148|kansas city, miss...|  23|127429| 0.09679905|\n",
      "| 250764|0380778556|         10|   4.0|   148|   cove, oregon, usa|NULL|250764|0.021571795|\n",
      "|  76352|0380778556|          0|   1.0|   148|olympia, washingt...|  58| 76352| 0.06522451|\n",
      "| 264317|0380778556|          0|   1.0|   148|portela de sacavï¿½...|  25|264317|0.102816366|\n",
      "|  51526|0380778556|          0|   1.0|   148|long beach, calif...|  34| 51526|0.056825895|\n",
      "| 127233|0380778556|          0|   1.0|   148|marietta, georgia...|  29|127233| 0.09300447|\n",
      "| 150896|0380778556|          8|   2.0|   148|vancouver, washin...|  30|150896|0.040286176|\n",
      "| 100906|0380778556|          0|   1.0|   148|seattle, washingt...|  34|100906| 0.21357739|\n",
      "| 115490|0380778556|          0|   1.0|   148|dekalb, illinois,...|NULL|115490| 0.15098327|\n",
      "|  98958|0380778556|          0|   1.0|   148|concord, californ...|NULL| 98958| 0.01261363|\n",
      "+-------+----------+-----------+------+------+--------------------+----+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "predictions.printSchema()\n",
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of predictions = 279866\n",
      "RMSE = 1.615744\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import isnan\n",
    "\n",
    "evaluator = RegressionEvaluator()\\\n",
    "    .setMetricName(\"rmse\")\\\n",
    "    .setLabelCol(\"rating\")\\\n",
    "    .setPredictionCol(\"prediction\")\n",
    "\n",
    "predictionsFiltered = predictions.where(~isnan(col(\"prediction\")))\n",
    "                                \n",
    "print(\"number of predictions = %i\" % predictionsFiltered.count())\n",
    "\n",
    "rmse = evaluator.evaluate(predictionsFiltered)\n",
    "\n",
    "print(\"RMSE = %f\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "#als2 = XALS()\\\n",
    "#    .setUserCol(\"userId\")\\\n",
    "#    .setItemCol(\"bookId\")\\\n",
    "#    .setRatingCol(\"rating\")\n",
    "\n",
    "pipeline = Pipeline().setStages([als])\n",
    "\n",
    "params = ParamGridBuilder()\\\n",
    "    .addGrid(als.rank, range(6, 24, 2))\\\n",
    "    .build()\n",
    "#    .addGrid(als.rank, [2, 5, 10])\\\n",
    "    \n",
    "\n",
    "cv = CrossValidator()\\\n",
    "    .setEstimator(als)\\\n",
    "    .setEstimatorParamMaps(params)\\\n",
    "    .setEvaluator(evaluator)\\\n",
    "    .setNumFolds(5)\n",
    "\n",
    "model = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6239172917349451,\n",
       " 1.6222531662774091,\n",
       " 1.6215336166588599,\n",
       " 1.6210818098192958,\n",
       " 1.6206428002718851,\n",
       " 1.6203356037407715,\n",
       " 1.6200454984194144,\n",
       " 1.61983906159896,\n",
       " 1.6197185058577894]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bestModel\n",
    "model.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = model.bestModel\n",
    "\n",
    "bestModel.write().overwrite().save('/data/books/bestModel-rank.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 1.612789\n"
     ]
    }
   ],
   "source": [
    "predictionsBestModel = bestModel.transform(test)\n",
    "bestModelRmse = evaluator.evaluate(predictionsBestModel)\n",
    "\n",
    "print(\"RMSE = %f\" % bestModelRmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6c6599878b36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRegressionEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegressionEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msetMetricName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rmse\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import isnan\n",
    "\n",
    "evaluator = RegressionEvaluator()\\\n",
    "    .setMetricName(\"rmse\")\\\n",
    "    .setLabelCol(\"listenCount\")\\\n",
    "    .setPredictionCol(\"prediction\")\n",
    "\n",
    "predictionsFiltered = predictions.where(~isnan(col(\"prediction\")))                                \n",
    "rmse = evaluator.evaluate(predictionsFiltered)\n",
    "\n",
    "print(\"RMSE = %f\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
