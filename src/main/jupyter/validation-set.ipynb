{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SPARK_HOME=/usr/hdp/current/spark2-client\n",
      "findspark initialized ...\n",
      "pyspark ready ...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%env SPARK_HOME=/usr/hdp/current/spark2-client\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "print('findspark initialized ...')\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr, col, column, max, min\n",
    "\n",
    "spark = SparkSession.builder.appName('mlonspark')\\\n",
    "    .config('spark.jars', '/opt/dev/target/ml-on-spark-1.0.jar')\\\n",
    "    .getOrCreate()\n",
    "\n",
    "print('pyspark ready ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bookId: integer (nullable = false)\n",
      " |-- ISBN: string (nullable = true)\n",
      "\n",
      "+------+----------+\n",
      "|bookId|      ISBN|\n",
      "+------+----------+\n",
      "|     0|0195153448|\n",
      "|     1|0002005018|\n",
      "|     2|0060973129|\n",
      "|     3|0374157065|\n",
      "|     4|0393045218|\n",
      "|     5|0399135782|\n",
      "|     6|0425176428|\n",
      "|     7|0671870432|\n",
      "|     8|0679425608|\n",
      "|     9|074322678X|\n",
      "+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books = spark.read.format(\"csv\")\\\n",
    "    .option(\"sep\",\";\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .load(\"/data/books/BX-Books.csv\")\n",
    "\n",
    "from pyspark.sql.functions import monotonically_increasing_id \n",
    "\n",
    "identifiedBooks = books.withColumn('bookId', monotonically_increasing_id().cast('int'));\n",
    "identifiedBooks = identifiedBooks.select(['bookId', 'ISBN'])\n",
    "identifiedBooks.printSchema()\n",
    "identifiedBooks.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User-ID: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users = spark.read.format(\"csv\")\\\n",
    "    .option(\"sep\",\";\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .load(\"/data/books/BX-Users.csv\")\n",
    "\n",
    "users = users.withColumn('userId', users['User-ID'].cast('int'))\n",
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User-ID: string (nullable = true)\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- Book-Rating: string (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- bookId: integer (nullable = false)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      "\n",
      "Pocet hodnoceni = 1031175\n",
      "+-------+----------+-----------+------+------+--------------------+----+------+\n",
      "|User-ID|      ISBN|Book-Rating|rating|bookId|            Location| Age|userId|\n",
      "+-------+----------+-----------+------+------+--------------------+----+------+\n",
      "| 276725|034545104X|          0|   0.0|  2966|   tyler, texas, usa|NULL|276725|\n",
      "| 276726|0155061224|          5|   5.0| 82022|seattle, washingt...|NULL|276726|\n",
      "| 276727|0446520802|          0|   0.0| 11054|h, new south wale...|  16|276727|\n",
      "| 276729|052165615X|          3|   3.0|103047|rijeka, n/a, croatia|  16|276729|\n",
      "| 276729|0521795028|          6|   6.0|103048|rijeka, n/a, croatia|  16|276729|\n",
      "| 276733|2080674722|          0|   0.0|123645|  paris, n/a, france|  37|276733|\n",
      "| 276744|038550120X|          7|   7.0|  9295|torrance, califor...|NULL|276744|\n",
      "| 276746|0425115801|          0|   0.0|  2030|       fort worth, ,|NULL|276746|\n",
      "| 276746|0449006522|          0|   0.0|   227|       fort worth, ,|NULL|276746|\n",
      "| 276746|0553561618|          0|   0.0|  1004|       fort worth, ,|NULL|276746|\n",
      "+-------+----------+-----------+------+------+--------------------+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.read.format(\"csv\")\\\n",
    "    .option(\"sep\",\";\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .load(\"/data/books/BX-Book-Ratings.csv\")\n",
    "\n",
    "ratings = ratings.withColumn('rating', ratings['Book-Rating'].cast('float'))\n",
    "\n",
    "ratings = ratings.join(identifiedBooks,\\\n",
    "    ratings['ISBN'] == identifiedBooks['ISBN'],\\\n",
    "    'inner').drop(identifiedBooks['ISBN'])\n",
    "\n",
    "ratings = ratings.join(users,\\\n",
    "    ratings['User-ID'] == users['User-ID'],\\\n",
    "    'inner').drop(users['User-ID'])\n",
    "                             \n",
    "ratings.printSchema()\n",
    "                             \n",
    "print(\"Pocet hodnoceni = %i\" % ratings.count())\n",
    "\n",
    "ratings.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.write.format(\"parquet\").mode(\"overwrite\").save(\"/data/books/ratings-all.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = ratings.randomSplit([0.7, 0.3])\n",
    "\n",
    "train.write.format(\"parquet\").mode(\"overwrite\").save(\"/data/books/ratings-train.parquet\")\n",
    "test.write.format(\"parquet\").mode(\"overwrite\").save(\"/data/books/ratings-test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
