{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SPARK_HOME=/usr/hdp/current/spark2-client\n",
      "findspark initialized ...\n",
      "pyspark ready ...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%env SPARK_HOME=/usr/hdp/current/spark2-client\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "print('findspark initialized ...')\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr, col, column, max, min\n",
    "\n",
    "spark = SparkSession.builder.appName('mlonspark')\\\n",
    "    .config('spark.executor.instances', '7')\\\n",
    "    .config('spark.jars', '/opt/dev/target/ml-on-spark-1.0.jar')\\\n",
    "    .getOrCreate()\n",
    "\n",
    "print('pyspark ready ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- artistId: integer (nullable = true)\n",
      " |-- listenCount: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = spark.read.load(\"/data/lastfm-dataset-360K/coo-data-train.parquet\")\n",
    "print(train.rdd.getNumPartitions())\n",
    "\n",
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----------+---------+\n",
      "|userId|artistId|listenCount|   scaled|\n",
      "+------+--------+-----------+---------+\n",
      "|   148|   90773|       52.0|1.1935484|\n",
      "|   148|  219383|       29.0|1.0875576|\n",
      "|   148|  289745|       17.0| 1.032258|\n",
      "|   148|  151567|       14.0|1.0184332|\n",
      "|   148|  215340|       14.0|1.0184332|\n",
      "|   148|  152525|       26.0|1.0737327|\n",
      "|   148|   17395|       15.0|1.0230415|\n",
      "|   148|  108389|       13.0|1.0138249|\n",
      "|   148|  108464|       11.0|1.0046083|\n",
      "|   148|  155233|       17.0| 1.032258|\n",
      "+------+--------+-----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from mlonspark.scaler import Scaler\n",
    "\n",
    "scaler = Scaler().setGroupCol(\"userId\").setInputCol(\"listenCount\").setOutputCol(\"scaled\")\n",
    "train = scaler.fit(train).transform(train)\n",
    "\n",
    "train.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|min(scaled)|max(scaled)|\n",
      "+-----------+-----------+\n",
      "|        1.0|        2.0|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan\n",
    "\n",
    "#nan = train.filter(isnan(\"listenCount\"))\n",
    "#nan.count()\n",
    "train.agg(min(\"scaled\"), max(\"scaled\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from mlonspark.alternating_least_square import AlternatingLeastSquare\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = AlternatingLeastSquare()\\\n",
    "    .setUserCol(\"userId\")\\\n",
    "    .setItemCol(\"artistId\")\\\n",
    "    .setRatingCol(\"scaled\")\\\n",
    "    .setNumUserBlocks(7)\\\n",
    "    .setNumItemBlocks(7)\\\n",
    "    .setMaxIter(10)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlternatingLeastSquare_4d98b163838babc1267a\n"
     ]
    }
   ],
   "source": [
    "model = als.fit(train)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "test = spark.read.load(\"/data/lastfm-dataset-360K/coo-data-test.parquet\")\n",
    "print(test.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- artistId: integer (nullable = true)\n",
      " |-- listenCount: float (nullable = true)\n",
      " |-- prediction: float (nullable = false)\n",
      "\n",
      "+------+--------+-----------+------------+\n",
      "|userId|artistId|listenCount|  prediction|\n",
      "+------+--------+-----------+------------+\n",
      "| 66166|     148|      325.0|-8.043704E-6|\n",
      "| 84435|     148|       99.0| 2.265907E-6|\n",
      "| 74849|     148|      146.0|5.1805373E-6|\n",
      "|117955|     148|       16.0|-9.346508E-6|\n",
      "|328713|     148|       82.0|-4.837967E-6|\n",
      "|310068|     148|      127.0|1.4713196E-6|\n",
      "|133763|     148|       35.0|1.0321969E-5|\n",
      "|179718|     148|      218.0|-9.583543E-6|\n",
      "|292575|     148|       23.0|4.6273835E-5|\n",
      "| 60056|     148|       71.0|-1.172958E-6|\n",
      "+------+--------+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "predictions.printSchema()\n",
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 662.300926\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import isnan\n",
    "\n",
    "evaluator = RegressionEvaluator()\\\n",
    "    .setMetricName(\"rmse\")\\\n",
    "    .setLabelCol(\"listenCount\")\\\n",
    "    .setPredictionCol(\"prediction\")\n",
    "\n",
    "predictionsFiltered = predictions.where(~isnan(col(\"prediction\")))                                \n",
    "rmse = evaluator.evaluate(predictionsFiltered)\n",
    "\n",
    "print(\"RMSE = %f\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
