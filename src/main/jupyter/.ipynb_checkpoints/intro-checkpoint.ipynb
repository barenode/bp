{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pro test byl vybran volne dostuppny http://www2.informatik.uni-freiburg.de/~cziegler/BX/[Book-Crossing Dataset]. Jedna se o data z celosvetove databaze knih https://www.bookcrossing.com[Bookcrossing]. Dataset je slozeny s nasledujicich CSV souboru:\n",
    "\n",
    "::BX-Users\n",
    "    Soubor obsahuje seznam uzivatelu. Tento seznam byl anonymizovan, tj. kazdy uzivatel je oznacen pouze celociselnym identifikatorem. V neterych pripadech jsou poskytnuta dodatecna demograficka data o veku a bydlisti.\n",
    "\n",
    "::BX-Books\n",
    "    Knihy jsou identifikovany pomoci prislusneho ISBN. Soubor obsahuje dodatecne informace jako jsou jmeno titulu, jmeno autora, datum vydani a vydavatele. K nekterym titulum je uveden odkaz na ilustraci z titulni stranky.\n",
    "\n",
    "::BX-Book-Ratings\n",
    "    Tento soubor obsahuje hodnoceni. Tyt hodnoceni jsou bud explicitni, vyjadrene na stupnici od 1-10, nebo implicitni, tyto maji prirazenou hodnotu 0. \n",
    "    \n",
    "Pred vlastni analyzou je nutne ulozit prislusna data do HDFS, sdileneho souboroveho systemu. K praci s HDFS existuje radkova utilita hdfs. Nejprve tedy vytvorime adresarovou strukturu a nasledne do techto adresaru nakopirujeme prislusne soubory z lokalniho souboroveho systemu.\n",
    "\n",
    "----\n",
    "hdfs dfs -mkdir /data\n",
    "hdfs dfs -mkdir /data/books\n",
    "hdfs dfs -copyFromLocal /opt/dev/src/main/jupyter/data/BX-Book-Ratings.csv /data/books\n",
    "hdfs dfs -copyFromLocal /opt/dev/src/main/jupyter/data/BX-Books.csv /data/books\n",
    "hdfs dfs -copyFromLocal /opt/dev/src/main/jupyter/data/BX-Users.csv /data/books\n",
    "----\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SPARK_HOME=/usr/hdp/current/spark2-client\n",
      "Spark je pripraven ...\n"
     ]
    }
   ],
   "source": [
    "%env SPARK_HOME=/usr/hdp/current/spark2-client\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "print('Spark je pripraven ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nejprve zjistime zakladni informace o soboru kde jsou ulozena jednotliva hodnoceni. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User-ID: string (nullable = true)\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- Book-Rating: string (nullable = true)\n",
      "\n",
      "Pocet hodnoceni = 1149780\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.read.format(\"csv\")\\\n",
    "    .option(\"sep\",\";\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .load(\"/data/books/BX-Book-Ratings.csv\")\n",
    "\n",
    "ratings.printSchema()\n",
    "\n",
    "print(\"Pocet hodnoceni = %i\" % ratings.count())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Nejprve jsme nacetli dany soubor do DataFrane struktury. Dataset ma tri sloupce User-ID, ISBN a Book-Rating. Prvni dva identifikuji uzivatele resp. knihu. Sloupec Book-Rating obsahuje prislusne hodnoceni. Ve vychozim stavu jsou vsechnz sloupce intepretovane jako retezcove promenne. Doporucovaci algoritmy nicmene vyzaduji aby hodnoceni byla numericka hodnota. Na datasetu tedy provedeme dodatecnou transaformaci, ktera vytvori dalsi slupec obsahujici numerickou repreyentaci slopuce Book-Rating."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
