{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pro test byl vybran volne dostuppny http://www2.informatik.uni-freiburg.de/~cziegler/BX/[Book-Crossing Dataset]. Jedna se o data z celosvetove databaze knih https://www.bookcrossing.com[Bookcrossing]. Dataset je slozeny s nasledujicich CSV souboru:\n",
    "\n",
    "::BX-Users\n",
    "    Soubor obsahuje seznam uzivatelu. Tento seznam byl anonymizovan, tj. kazdy uzivatel je oznacen pouze celociselnym identifikatorem. V neterych pripadech jsou poskytnuta dodatecna demograficka data o veku a bydlisti.\n",
    "\n",
    "::BX-Books\n",
    "    Knihy jsou identifikovany pomoci prislusneho ISBN. Soubor obsahuje dodatecne informace jako jsou jmeno titulu, jmeno autora, datum vydani a vydavatele. K nekterym titulum je uveden odkaz na ilustraci z titulni stranky.\n",
    "\n",
    "::BX-Book-Ratings\n",
    "    Tento soubor obsahuje hodnoceni. Tyt hodnoceni jsou bud explicitni, vyjadrene na stupnici od 1-10, nebo implicitni, tyto maji prirazenou hodnotu 0. \n",
    "    \n",
    "Pred vlastni analyzou je nutne ulozit prislusna data do HDFS, sdileneho souboroveho systemu. K praci s HDFS existuje radkova utilita hdfs. Nejprve tedy vytvorime adresarovou strukturu a nasledne do techto adresaru nakopirujeme prislusne soubory z lokalniho souboroveho systemu.\n",
    "\n",
    "----\n",
    "hdfs dfs -mkdir /data\n",
    "hdfs dfs -mkdir /data/books\n",
    "hdfs dfs -copyFromLocal /opt/dev/src/main/jupyter/data/BX-Book-Ratings.csv /data/books\n",
    "hdfs dfs -copyFromLocal /opt/dev/src/main/jupyter/data/BX-Books.csv /data/books\n",
    "hdfs dfs -copyFromLocal /opt/dev/src/main/jupyter/data/BX-Users.csv /data/books\n",
    "----\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SPARK_HOME=/usr/hdp/current/spark2-client\n",
      "Spark je pripraven ...\n"
     ]
    }
   ],
   "source": [
    "%env SPARK_HOME=/usr/hdp/current/spark2-client\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "print('Spark je pripraven ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nejprve zjistime zakladni informace o soboru kde jsou ulozena jednotliva hodnoceni. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User-ID: string (nullable = true)\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- Book-Rating: string (nullable = true)\n",
      "\n",
      "Pocet hodnoceni = 1149780\n",
      "root\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- Book-Title: string (nullable = true)\n",
      " |-- Book-Author: string (nullable = true)\n",
      " |-- Year-Of-Publication: string (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- Image-URL-S: string (nullable = true)\n",
      " |-- Image-URL-M: string (nullable = true)\n",
      " |-- Image-URL-L: string (nullable = true)\n",
      "\n",
      "Pocet knih = 271379\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.read.format(\"csv\")\\\n",
    "    .option(\"sep\",\";\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .load(\"/data/books/BX-Book-Ratings.csv\")\n",
    "\n",
    "ratings.printSchema()\n",
    "\n",
    "print(\"Pocet hodnoceni = %i\" % ratings.count())\n",
    "\n",
    "books = spark.read.format(\"csv\")\\\n",
    "    .option(\"sep\",\";\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .load(\"/data/books/BX-Books.csv\")\n",
    "\n",
    "books.printSchema()\n",
    "\n",
    "print(\"Pocet knih = %i\" % books.count())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Nejprve jsme nacetli dany soubor do DataFrane struktury. Dataset ma tri sloupce User-ID, ISBN a Book-Rating. Prvni dva identifikuji uzivatele resp. knihu. Sloupec Book-Rating obsahuje prislusne hodnoceni. Ve vychozim stavu jsou vsechnz sloupce intepretovane jako retezcove promenne. Doporucovaci algoritmy nicmene vyzaduji aby hodnoceni byla numericka hodnota. Na datasetu tedy provedeme dodatecnou transaformaci, ktera vytvori dalsi slupec obsahujici numerickou repreyentaci slopuce Book-Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|User-ID|count|\n",
      "+-------+-----+\n",
      "|  11676|13602|\n",
      "| 198711| 7550|\n",
      "| 153662| 6109|\n",
      "|  98391| 5891|\n",
      "|  35859| 5850|\n",
      "+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "ratings.groupBy(\"User-ID\").count().orderBy(col(\"count\").desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------------+-------------------+\n",
      "|count|          Book-Title|    Book-Author|Year-Of-Publication|\n",
      "+-----+--------------------+---------------+-------------------+\n",
      "| 2502|         Wild Animus|   Rich Shapero|               2004|\n",
      "| 1295|The Lovely Bones:...|   Alice Sebold|               2002|\n",
      "|  883|   The Da Vinci Code|      Dan Brown|               2003|\n",
      "|  732|Divine Secrets of...|  Rebecca Wells|               1997|\n",
      "|  723|The Red Tent (Bes...|  Anita Diamant|               1998|\n",
      "|  647|     A Painted House|   John Grisham|               2001|\n",
      "|  639|                null|           null|               null|\n",
      "|  615|The Secret Life o...|  Sue Monk Kidd|               2003|\n",
      "|  614|Snow Falling on C...| David Guterson|               1995|\n",
      "|  586| Angels &amp; Demons|      Dan Brown|               2001|\n",
      "|  585|Where the Heart I...|   Billie Letts|               1998|\n",
      "|  571|Harry Potter and ...|  J. K. Rowling|               1999|\n",
      "|  568|The Pilot's Wife ...|   Anita Shreve|               1999|\n",
      "|  552|House of Sand and...|Andre Dubus III|               2000|\n",
      "|  529|            The Firm|   John Grisham|               1992|\n",
      "|  526|Girl with a Pearl...|Tracy Chevalier|               2001|\n",
      "|  523|   The Pelican Brief|   John Grisham|               1993|\n",
      "|  519|   The Joy Luck Club|        Amy Tan|               1994|\n",
      "|  517|      A Time to Kill|   JOHN GRISHAM|               1992|\n",
      "|  506|Interview with th...|      Anne Rice|               1993|\n",
      "+-----+--------------------+---------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.groupBy(\"ISBN\")\\\n",
    "    .count()\\\n",
    "    .join(books, ratings[\"ISBN\"] == books[\"ISBN\"], \"left_outer\")\\\n",
    "    .select(\"count\", \"Book-Title\", \"Book-Author\", \"Year-Of-Publication\")\\\n",
    "    .orderBy(col(\"count\").desc())\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
