
== Implementace vybraných algoritmů v řešené oblasti

=== Výběr vhodných technologií

Před samotnou implementací je třeba zvolit vhodné technologie. Jedná se primárně o volbu programovacího jazyka a příslušných vývojových nástrojů. Pro vývoj v prostředí Apache Spark existuje řada technologií, které se svojí funkcionalitou částečně nebo úplně překrývají. Jejich výběru je proto třeba věnovat zvýšenou pozornost.   

==== Výběr programovacího jazyka

Spark podporuje několik různých jazyků a to jsou Scala, Java, Python a R. Scala je nativní jazyk Sparku a jeho přidružených knihoven. Jedná se o takzvaný JMV jazyk, který potřebuje ke svému běhu nainstalovanou Javu, konkrétně její běhové prostředí. Zdrojový kód v jazyce Scala se při kompilaci převede do Java byte kódu. To znamená, že se aplikace distribuuje ve formě java archivů takzvaných jarů. K vývoji Spark aplikací můžeme tedy použít také přímo Javu samotnou, aplikace napsané v Javě mohou používat knihovny napsané ve Scale a naopak. Zejména podpora funkcionálního programování a ad-hoc struktur činí ze Scaly nejvhodnější jazyk pro Spark. Python je velice populární jazyk určený pro rychlé prototypování. V posledních letech se stal víceméně standardem pro experimentování v oblasti umělé inteligence a strojového učení. Python má k dispozici mnoho specializovaných knihoven jako jsou Sciki-learn nebo TensorFlow. Python není nativním jazykem Sparku, místo toho používá specializovanou knihovnu Py4J pro interakci s JVM. Jazyk R je naopak velice populární v rámci statistické komunity. Pro práci s tímto jazykem existují dokonce dvě knihovny, SparkR distribuovaná spolu se Sparkem a dále sparklyr, vyvíjená týmem nástroje RStudio.

Pro vývoj aplikace byl vyhodnocen jako nejvhodnější jazyk Scala. Při vývoji se budeme moci nechat inspirovat praktikami použitými při vývoji Sparku samotného, zejména jeho knihoven určených pro strojové učení. Dále budeme používat Python v rámci experimentální fáze projektu k optimalizaci hyper parametrů.  

==== Výběr nástroje pro automatizaci buildů aplikace

Nástroj pro automatizaci buildů zaštiťuje kompletní cyklus sestavení aplikace. Toto zahrnuje zejména kompilaci zdrojového kódu a spuštění kompletní sady projektových testů. Na závěr cyklu nástroj vytvoří konečnou verzi aplikace a uloží ji pod příslušným identifikátorem verze do sdíleného repositáře. Pro aplikace vyvíjené v jazyce Scala existuje specifický nástroj *sbt*, dále je možné použít některý z nástrojů uřčený přímo pro jazyk Java spolu s příslušným rozšířením pro Scalu. Těchto nástrojů je celá řada, zřejmě nejpoužívanější jsou Apache Maven a Gradle. Pro náš projekt byl vybrán nástroj Maven, zejména proto, že je použit i v rámci vývoje Sparku samotného. 

==== Výběr IDE

Vedle nástroje pro automatizaci buildů budeme dále potřebovat integrované vývojové prostředí (IDE). Takové prostředí usnadňuje psaní zdrojového kódu, spouštění jednotlivých unit testů atd. Na toto prostředí existuje několik základních požadavků, které musí splňovat pro vývoj Spark aplikací:

. Vestavěná podpora Apache Maven. IDE by mělo být schopné automaticky naimportovat informace z Maven deskriptoru aplikace (pom.xml). Primárně se jedná o sadu knihoven, závislostí projektu, která by měla být nadefinovaná na jediném místě. Vzhledem ke své popularitě, je podpora Apache Maven zahrnuta ve většině současných Java IDE.

. Podpora Scaly. Scala je jen jeden z mnoha JVM jazyků a je mnohem méně používaná než Java samotná. Kvalitní podpora toho jazyka není úplně bežná.

. Podpora Scala testovacího rámce. Ačkoliv je Apache Maven skvělý nástroj a při sestavování aplikace spustí kompletní sadu unit testů. Při implementaci samotné potřebujeme jemnější kontrolu nad tím, který test spouštíme. Zvolené IDE by mělo tuto možnost podporovat a umožnit nám spouštět testy jednotlivě dle potřeby. V našem projektu použijeme stejný testovací rámec jako je použitý ve Sparku samotném. To nám dovolí použít stejné konstrukty, bázové třídy unit testů, usnadňující automatické vytváření a rušení testovacích instancí Sparku.

Do užšího výběru postoupili dva kandidáti. První je Scala IDE, vývojové prostředí postavené na populární platformě Eclipse. Druhé je neméně populární vývojové prostředí IntelliJ IDEA. Scala IDE ve verzi 4.7.0 splňovalo první dva z uvedených požadavků, nicméně se i přes urputnou snahu nepodařila uspokojivě vyřešit podpora unit testů. IntelliJ IDEA spolu se Scala pluginem splnila všechny tři požadavky na výbornou. Pro vývoj aplikace tedy použijeme nástroj IntelliJ IDEA.