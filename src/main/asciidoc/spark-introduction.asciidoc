
==  Apache Spark

Apache Spark je unifikovaný výpočetní systém pro paralelní zpracování dat na počítačových clustrech. Spark nabízí bohaté API pro datové operace jako je filtrování, spojováni (join), seskupování a agregace. Toto API je dostupné pro řadu populárních programovacích jazyků jako jsou Java, Python, C# a R. Spark je aktuálně nejaktivněji vyvíjeným open source projektem v této oblasti s vice nez tisícem aktivních vývojářů.

Filozofie Sparku je rozdílná od předcházejících platforem pro zpracovávání velkých objemů dat jako je například Hadoop, tento zahrnuje jak výpočetní systém (MapReduce) tak i úložiště dat (HDFS). Obě tyto části jsou spolu úzce provázané a je obtižné provozovat jednu část bez té druhé. Ačkoliv je možné Spark bez problémů provozovat nad HDFS není na tomto úložném systému nijak závislý a je možné ho používat i spolu s jinými zdroji dat. Jednou z motivací tohoto přístupu je, že data které je potřeba analyzovat, jsou typicky již uložena v rozdílných formátech v řadě různých úložných systémů. Přesouvání těchto dat pro analytické účely může byt zejména při vyšších objemech nepraktické. Spark je proto postaven tak aby byl přístup k datům co nejvíce transparentní.

Klíčovou vlastností Sparku je, že samotné provedení sekvence datových operací je nejprve optimalizováno. Tato optimalizace zajistí co možná nejefektivnější řetězec zpracování s využítím operační paměti pro mezivýsledky. To je velkou výhodou v rychlosti výpočtu oproti MapReduce kde se v každém kroku výsledky persistují a je nutné je v následujícím kroku řetězce znovu načíst.    

V diagramu <<spark-structure>> je zobrazena základní struktura Sparku. Základem je nízkoúrovňové API pro práci s datasety, RDD (Resilient Distributed Dataset) volně přeloženo jako pružný distribuovaný dataset. Dalšim patrem je strukturované API, přidané v druhé generaci Sparku. Na RDD a strukturovaném API je postavena řada specifických modulů, které jsou součástí standartní distribuce Sparku. Mezi tyto moduly patří:

* MLlib pro podporu strojové učení. 
* Structured Spark Streaming pro podporu datových proudů.
* GraphX pro podporu analýzy grafů.     

[[spark-structure]]
image::spark-structure.png[title="Struktura Sparku", pdfwidth="75%"]


=== Spark API

==== RDD

RDD (Resilient Distributed Dataset) je základní konstrukt Spark API. Představuje neměnnou kolekci záznamů, rozdělenou do částí, které mohou být nezávisle paralelně zpracovány. Tyto části, takzvané partitions, jsou typicky rozložené na více uzlů v rámci výpočetního clustru. Jednotlivé záznamy jsou klasické Java, Python nebo Scala objekty. Při operaci nad daným RDD je každé partititon přiřazen právě jeden výkonný proces. RDD API dále disponuje řadou operací pro manipulaci s daty, které se dělí do dvou základních skupin:

Transformace::
    Ve Sparku jsou zdrojová data typicky neměnná. Pokud chceme provést úpravy nad RDD, definujeme jednu nebo více takzvaných transformací. Tyto transformace instruují Spark jak má změnit zdrojová data. Důležitý je fakt, že samotná transformace pouze definuje jak se mají data změnit, transformace samotná se ale instantně neiniciuje. Komplexní operace nad daty většinou zahrnují celý řetězec atomických transformací. Spark počká na akci která si vyžádá transformovaný RDD, z řetězce transformací následně automaticky vyhodnotí optimalní plan provedení a teprve potom tranformuje zdrojový RDD. Transformace se dále dělí na dva zakladní typy, na úzké a široké. Úzké transformace se aplikují na jednu partition nezávisle na ostatních. Výsledkem je právě jedna cílová partition, typicky uložená na stejném počítači v rámci clustru. Úzké transformace se tedy nechají jednoduše paralelizovat. Při široké transformaci je transformovaná partition závislá na ostatních partition, typicky uložených na ostatních počítačích. Je tedy nutné provést takzvané přeskládání (shuffle) a v rámci clusterové sítě přenést potřebná data.           

Akce::
    Akce jsou metody RDD API, které spouští samotný výpočet, při kterém se aplikují definované transformace na zdrojový RDD. 

.TransformationExample1.scala 
[source, scala, numbered]
----
include::{scala-test-dir}/mlonspark/SCSuite.scala[tags=spark-example-1]
----
   
---- 
(2) MapPartitionsRDD[3] at mapValues at TransformationExample1:20 []
 |  ShuffledRDD[2] at groupByKey at TransformationExample1:20 []
 +-(2) MapPartitionsRDD[1] at map at TransformationExample1:18 []
    |  ParallelCollectionRDD[0] at parallelize at TransformationExample1:2 []
----
    
----
(1,5)
(0,4)
----

==== Strukturované API

Do duhé generace přidali autoři Sparku takzvané strukturované API. Základním konstruktem tohoto API je DataFrame. DataFrame reprezentuje tabulku složenou z řádků a sloupců, tato tabulka se ale, stejně jako RDD, může rozkládat na mnoha počítačích v rámci výpočetního clustru. DataFrame také jako RDD používá pro operace s daty akce a transformace. Strukturované API by mělo být preferovaným způsobem používání Sparku, je uživatelsky přívětívější, vysoce optimalizované a odstiňuje uživatele od náročnějších detailů. Nicméně pokud je třeba mít přímou kontrolu nad tím, jak jsou data fyzicky uložena v rámci clustru, je nutné použít RDD API.
Stejný koncept jako DataFrame, omezený na jediný počítač, používajá API jako Python Pandas nebo R DataFrames. Toto usnadňuje používání Sparku uživatelům se znalostmi těchto nástrojů, například jako doplňující nástroj pro práci s velkými objemy dat. 


=== Spark Aplikace

Spark aplikace se sklada z ridiciho procesu a sady vykonnych procesu. Ridici proces ja srdcem cele aplikace. Je zodpovedny za analyzu a distribuci ukolu jednotlivym vykonnych procesum. Dale udrzuje veskere spjate s danou apliaci. Vykonne procesy jsou zodpovedne za zpracovani ukolu, ktery jim priradi ridici proces a za reportovani stavu tohoto ukolu zpet ridicimu processu. Cluster pocitacu, ktere Spark vyuzije pro vykonani dane aplikace je rizeny cluster managerem. Tento manager ridi pristup k prostredkum clusteru a prirazuje jeho zdroje jednotlivym aplikacim. V ramci jednoho clusteru muze tedy bezet vice Spark aplikaci zaroven. Spark neni zavisly na jednom konkretnim cluster manageru, v dobe psani prace podporoval YARN, Mesos a vlastni takzvany Spark standalone cluster manager. Vyvojar Spark aplikace je odstineny od toho na jake ukoly bude aplikace rozdelena nebo na kterych pocitacich v ramci clustru budou tyto ukolly vykonany. O vse se transparente postara Spark spolu s pouzitym cluster manazerem.                                  


==== Odeslani aplikace

Aplikace samotna je typicky zkompilovana java knihovna obsahujici spustitelnou tridu. Zpusobu jak spustit aplikaci je mnoho, zakladni z nich je pouzit utilitu spark-submit z prikazove radky. V teto chvili spoustime proces na klientskem pocitaci, tento proces kontaktuje prislusny cluster manager a zazada si o prostredky pro ridici proces. Cluste manager umisti ridici proces samotny na nektery z dostupnych pocitacu. Proces spusteny z prikazove radky na klientskem pocitaci je dokoncen a aplikace je spustena. Prubezny stav aplikace je mozne sledovat pomoci dodatecnych dotazu na prislusny cluster mamanazer. 

V teto fazi je ridici proces umisteny na nekterem uzlu v clusteru. Ridici proces nasledne spusti uzivatelsky kod (spustitelna trida v ramci odeslane JARu). Tento kod musi obsahovat incializaci tridy SparkSession. SparkSession nasledne komunikuje s cluster manazerem a vazada si spusteni jednotlivych vykonnych procesu. Po inicializaci a spusteni jednotlivych vykonnych procesu odesle cluster manazer relevantni informace o jejich umisteni zpet ridicimu procesu.

V teto chvili mame inicializovany Spark cluster slozeny z jednoho ridiciho procesu a sady vykonnych procesu. Ridici proces prideluje jednotlive ukoly vykonnym procesum. Vykonne procesy komunikuji mezi sebou, vykonavaji ukoly a vymenuji is potrebna data. o dokonceni prideleneho ukolu reportuji vysledny status pzet ridicimu procesu.

Po dokonceni behu aplikace, je ridici proces ukoncen s vyslednym stavem,. Cluster manager nasledne ukonci vsechny pridelene vykonne procesy. V teto chvili je mozne zjistit vysledny status dotazem na prislusny cluster manager.


