
=== Spark a Hadoop [[spark-hadoop]]

Apache Hadoop je open source implementací technik popsaných v materiálech vydaných společností Google cite:[GFS, MAPRED]. Jádro tohoto projektu obsahuje tři základní komponenty. Distribuovaný souborový systém HDFS, systém na správu prostředků počítačových clustrů YARN a výpočetní systém MapReduce. Od svého vzniku se k těmto nástrojům přidala řada dalších nástrojů a knihoven adresujících další oblasti užití. Jedním z těchto nástrojů je i Apache Spark, aktuálně jeden z nejpopulárnějších výpočetních nástrojů v celém Hadoop ekosystému. Při nasazení v rámci Hadoopu je Spark závislý na clustr manažeru YARN, dále primárně pracuje s daty uloženými v HDFS ačkoliv může využívat i data z jiných zdrojů.     

==== HDFS

Hadoop Distributed File System (HDFS) je distribuovaný souborový systém pro Hadoop, optimalizovaný pro ukládání velkých objemů dat cite:[HADOOP]. Při ukládání dat, HDFS rozdělí soubor do bloků konstantní, nakonfigurované délky, standartně 128 MB. Následně uloží repliky každého bloku na nakonfigurovaný počet počítačů v clustru, standartně 3. Replikace bloků dat se provádí jednak z důvodu zálohy ale také pro umožnění paralelních výpočtů nad daty na více počítačích v clustru. Každý z počítačů v clustru má nainstalovanou HDFS službu DataNode, která je zodpovědná za ukládání dat na disk a jejich následné načítání. DataNode služba zná jenom bloky, které má uložené a jejich identifikátory, ale neudržuje informace o tom, které bloky patří ke kterým uloženým souborům. Tyto informace jsou udržovány koordinační službou NameNode, která udržuje informace o mapování souboru do bloků, dále také udržuje metadata o souborech jako jsou například přístupová práva. 

HDFS má vysokou průchodnost. Pokud chce klient uložit soubor, nejprve kontaktuje NameNode a obdrží list DataNode služeb pro každý blok. Samotný zápis následně probíhá mezi klientem a DataNode. Po zapsání bloku na první DataNode tento automaticky replikuje tento blok na další počítače a neblokuje klienta v dalším zápisu. Stejně tak při načítání souboru klient komunikuje přímo s DataNode. 

HDFS je tolerantní k chybám. Pokud dojde k havárii disku, počítače nebo dokonce celého racku, NameNode úkoluje jednotlivé DataNode služby, které drží repliky ztracených dat, aby rozkopírovaly ztracené bloky na další počítače v clustru. Tím se zajistí nastavený replikační faktor pro každý blok cite:[AMDP].  

    
==== YARN

Yet Another Resource Negotiator (YARN) je centralizovaný clustr manažer pro Hadoop. Každý z počítačů v clustru má nainstalovanou YARN službu NodeManager, která komunikuje s řídící službou ResourceManager. Každý NodeManager reportuje službě ResourceManager kolik zdrojů v podobě operační paměti a procesorových jader je dostupných na daném počítači. Zdroje na jednotlivých počítačích jsou rozdělené do logických celků takzvaných kontejnerů, kde má každý kontejner  přidělené určité množství zdrojů (například 4 procesorová jádra a 8GB RAM). NodeManager je zodpovědný za vytváření a monitorovani kontejnerů na daném počítači a jejich ukončení pokud překročí přidělené zdroje. Aplikace které potřebují provést výpočet v rámci clustru nejprve kontaktují službu ResourceManager a zažádají si o jeden kontejner na kterém spustí vlastní koordinační proces nazývaný ApplicationMaster (AM). ApplicationMaster si následně zažádá ResourceManager o potřebné kontejnery na kterých provede výpočet samotný cite:[AMDP].  

Jak již bylo řečeno, jednotlivé soubory jsou rozdělené v HDFS do bloků. Při zpracování těchto souborů Sparkem se tyto bloky mapují přímo na Spark partition. Každý z těchto bloků/partitions zpracovává právě jeden YARN kontejner obsahující výkonný proces Sparku. Při zpracování jsou tyto procesy umístěné lokálně k datům aby se co nejvíce eliminovala síťová komunikace.  
  