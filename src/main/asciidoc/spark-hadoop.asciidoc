
=== Spark a Hadoop [[spark-hadoop]]



==== HDFS

Hadoop Distributed File System (HDFS) je distribuovaný souborový systém pro Hadoop, optimalizovaný pro ukládání velkých objemů dat cite:[HADOOP]. Při ukládání dat, HDFS rozdělí soubor do bloků konstantní, nakonfigurované délky, standartně 128 MB. Následně uloží repliky každého bloku na nakonfigurovaný počet počítačů v clustru, standartně 3. Replikace bloků dat se provádí jednak z důvodu zálohy ale také pro umožnění paralelních výpočtů nad daty na vice počítačítačích v clustru. Každý z počítačů v clustru má nainstalovanou HDFS službu DataNode, která je zodpovědná za ukládání dat na disk a jejich následné načítání. DataNode služba zná jenom bloky, které má uložené a jejich identifikátory ale neudržuje informace o tom, které bloky patří ke kterým uloženým souborům. Tyto informace jsou udržovány koordinační službou NameNode, která udržuje informace o mapování souboru do bloků, dále také udržuje metadata o souborech jako jsou například přístupová práva. 

HDFS má vysokou průchodnost. Pokud chce klient uložit soubor, nejprve kontaktuje NameNode a obdrží list DataNode služeb pro každý blok. Samotný zápis následně probíha mezi klientem a DataNode. Po zapsání bloku na první DataNode tento automaticky replikuje tento blok na další počtače a neblokuje klienta v dalším zápisu. Stejně tak při načítání souboru klient komunikuje přímo s DataNode. 

HDFS je tolerantní k chybám. Pokud dojde k havárii disku, počítače nebo dokonce celého racku, NameNode úkoluje jednotlivé DataNode služby, které drží repliky ztracených dat, aby rozkopírovaly ztracené bloky na další počítače v clustru. Tím se zajistí nastavený replikacní faktor pro každý blok cite:[AMDP].  

    
==== YARN

Yet Another Resource Negotiator (YARN) je centralizovaný clustr manažer pro Hadoop. Každý z počítačů v clustru má nainstalovanou YARN službu NodeManager, která komunikuje s řídící službou ResourceManager. Každý NodeManager reportuje službe ResourceManager kolik zdrojů v podobě operační paměti a procesorových jader je dostupných na daném počítači. Zdroje na jednotlivých počitačích jsou rozdělené do logických celků takzvaných kontainerů, kde má každý kontainer  pridělené určité množství zdrojů (například 4 procesorová jádra a 8GB RAM). NodeManager je zodpovědný za vytváření a monitorovani kontainerů na daném počítači a jejich ukončení pokud pRekroci pridelene zdroje.
Aplikace ktere potrebuji provest vypocet v ramci slustru nejdrive kontaktuji sluzbu ResourceManager a zazadaji si o jeden kontainer na kterem spusti vlastni koordinacni proces nazyvany ApplicationMaster (AM). ApplicationMaster si nasledne zazadata ResourceManager o potrebne konteinery na kterych provede vypocet samotny.