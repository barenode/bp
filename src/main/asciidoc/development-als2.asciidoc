
==== Estimator

Hyper paramtery mají vliv na vısledné predikce hodnocení, jejich optimální hodnoty jsou závislé na datasetu, pro kterı vyváøíme model. Pøesné hodnoty odvodíme a pøi experimentování, typicky pomocí køíové validace <<CH ML>>. Algoritmus bude podporovat následující vstupní hyper parametry:

rank::
    Rank urèuje dimenzi faktorovıch vektorù. Tato dimenze je vdy stejná jak pro uivatele tak i pro produkty. Pokud je velikost faktorovıch vektorù pøíliš nízkı, model bude také pøíliš zjedndušenı a nebudé podávat optimalní predikce. Na druhou stranu pokud bude tento poèet pøíliš velkı, mùe dojít k takzvanému pøeuèení, kdy model bude pøíliš spjatı s trénovacími daty. Vıhozí hodnota je 10.
    
alpha::
    Alpha nastavuje pomìr nárùstu dùvìry v hodnocení, viz <<CH ALS>>. Vıchozí hodnota je 0.1.
    
regParam::
    Regularizaèní parametr zabraòuje pøeuèení modelu. Hodnota 0 má za následek, e se pøi vıpoètu regularizace neaplikuje. Vıchozí hodnota je 0.1.  
    
Tréningové parametry nemají pøímo vliv na nastavení vıpoètu ale mùeme pomocí nich kontrolovat jak budou data distribuována v rámci vıpoèetního clustru. Data jsou pøed vıpoètem samotnım rozdìlìna do blokù. Tyto bloky jsou vlastnì partition a jsou následnì zpracovávány paralelnì. Zvolenı poèet blokù spoilu s kapacitou vıpoèetního clustru mají zásadní dopad na to, jak dlouho zabere vytvoøení modelu. Dle <<HDG>> je optimalní velikost bloku mezi jedním a pìti miliony hodnocení. Náš algoritmus bude podporovat následující trénovací parametry:

numUserBlocks::
    Poèet blokù do kterıch budou rozdìleni uivatelé, vıchozí hodnota je 10. 

numItemBlocks::
    Poèet blokù do kterıch budou rozdìlené produkty, vıchozí hodnota je 10.
    
maxIter::
    Poèet iterací pøi vıpoètu. V kadé iteraci se provede vıpoèet uivatelskıch a produktovıch faktorù. Po urèitém poètu iterací se ji vısledné faktory nemìní a nemá smysl ve vıpoètu pokraèovat. Optimální poèet iterací zjistíme napøíklad pomocí RMSE. Vıchozí hodnota je 10.     

Další, pomocné parametry identifikují sloupce poadované pro vıpoèet v rámci vstupního datasetu:

userCol::
    Jméno sloupce ve vstupním datasetu, kterı obsahuje numerickı identifikátor uivatele.

itemCol::
    Jméno sloupce ve vstupním datasetu, kterı obsahuje numerickı identifikátor produktu. 

rating::
    Jméno sloupce ve vstupním datasetu, kterı obsahuje hodnocení. Hodnocení mohou nabıvat reálnıch, nezápornıch hodnot.
        
        
=====  Struktura blokù  

Pro práci s bloky zvolíme rozdílnou terminologii ne rozdìlení na uivatele a produkty. Vzhledem k povaze algoritmu, kdy se støídavì provádí vıpoèet faktorù zvlaš pro uivatele a zvlaš pro proukty, pouijeme pro oba stejnı algoritmus a vytvoøíme pro nì analogické struktury. Jednou budou jako cíl vıpoètu uivatelské faktory, které pouijí jako zdroj pro vıpoèet faktory produktové. Podruhé to bude naopak. Dále tedy budeme pro vysvìtlení algoritmu pouívat termíny zdroj a cíl. 

Pro vyhodnoceni ciloveho bloku vytvorime jednoduchou hashovaci funkci. Tato rozdeli hodnoceni rovnomerne dle zvoleneho celkove poctu bloku. Kazdemu uzivateli resp polozce prideli cilovy blok na zaklade jejich celociselneho identifikatoru. Vysleden cislo bloku bude take cele cislo v rade zacinajici nulou. Id bloku tedy take zaroven jeho indexem v sade prislusnych bloku. 

[[als_block_diagram]]
image::als_block_diagram02022020.jpg[title="Diagram bloku hodnoceni", pdfwidth="75%"]

V diagramu <<als_block_diagram>> je zobrazena struktura bloku hodncení. Pro kadı blok vzniknou tøi nezávislé struktury:

Blok::
    Základní struktura, obsahující pøíslušná hodnocení. Tyto bloky se inicializují na zaèátku vıpoètu na základì vstupních dat. Data v nich zùstávají konstantní pøes všechny iterace vıpoètu. Vıpoèet se provádí lokálnì na poèítaèi kde jsou tyto data uloena, není tedy tøeba tyto bloky v prùbehu vıpoètu opakovanì pøenášet po síti v rámci vıpoèetního clustru. V tìchto blocích je jeden z identifikátorù zvolen jak zdrojovı a druhı jako cílovı. Hodnocení jsou seøazena dle zdrojového identifikátoru (vzestupnì). Data v bloku jsou  zkomprimována do takzvané CSC (compressed sparse column) struktury. Vzhledem k tomu, e jeden zdrojovı identifikátor mùe bıt v datech zastoupenı nìkolikrát, vybereme nejprve unikátní zdrojové identifikátory viz. (Zdrojové ID) <<als_block_diagram>>. K tìmto identifikátorùm pøiøadíme ukazatel do bloku hodnocení. Tento ukazatel urèuje ke kterım hodnocením pøíslušné zdrojové ID patøí. Cílovı identifikátor nahradíme v datech identifikátorem cílového bloku a lokálním indexem. Lokální index urèuje index seøazenıch unikatních cílovıch id pro dany zdrojovı a cílovı blok. Tyto idenitifikátory provazují zdrojovı blok a cílovı meta blok.
    
Blok faktorù::
    Pro kadé unikátní zdrojové id v rámci propojeného bloku bude v tomto bloku právì jeden faktorovı vektor. Dimenze tìchto vektorù je dána zvolenım rankem, typicky se jedná o relativnì nízkou hodnotu, viz. vıchozí hodnota 10. Tyto faktory se pøepoèítávají v rámci kadé iterace a jsou následnì pouity jako zdroj pro vıpoèet cílovıch faktorù. Tyto bloky je tedy nutné v prùbìhu vıpoètu distribuovat v rámci clustru. Blok faktorù inicializujeme na zaèátku vıpoètu a jednotlivım faktorùm pøiøadíme náhodná reálná èísla.
    
Meta blok::
    Na základì dat v bloku vytvoøíme takzvanı metablok. Metabloky mezi sebou provazují zdrojové a cílové bloky. Reálnì se jedná o dvourozmìrné pole kde je záznam pro kadı cílovı blok. V tìchto záznamech jsou zdrojová id, pro které existuje hodnocení v daném zdrojovém a cílovém bloku. 
       
[[als_block_connection]]
image::als_block_connection02022020.jpg[title="Diagram propojeni bloku", pdfwidth="75%"]

V diagramu <<als_block_connection>> je zobrazené propojené mezi zdrojovımi a cílovımi bloky. Pokud chceme spoèítat zdrojovı faktor pro jedno zdrojové id (30)musíme do lineárního systému zahrnout vèechny cílové faktory (cílové id 5, 12) pro které existuje hodnocení pro dané zdrojové a cílové id. Tyto mohou bıt typicky v rozdílnıch cílovıch blocích (1, 4) uloenıch na rozdílnıch poèítaèích v rámci clustru.


=====  Rozdìlení hodnoceni do blokù 

Jako top level vstup do algoritmu pouijeme strukturované API jako preferovanı zpùsob od druhé generace Sparku. Dataset musí obsahovat sloupce identifikované vstupními parametry userCol, itemCol a rating. V rámci algoritmu samotného ale pro práci s hodnoceními pouijeme RDD API. Toto API niší úrovnì nám, narozdíl od doporuèovaného, strukturovaného API, dává monost øídit rozloení dat v rámci clustru. Jako vstup do èásti algoritmu, kterı nám rozdìlí hodnocení do pøíslušnıch blokù, nejprve pøevedeme vstupní dataset do RDD uspoøádanıch trojic:

[source, scala, numbered]
----
include::{scala-dir}/mlonspark/AlternatingLeastSquare.scala[tags=dataset-to-rdd]
----

Tato trojice se skládá ze zdrojového id (srcId), ciloveho id (dstId) a hodnocení. Nejprve vytvoøíme uivatelské bloky, tj. jako zdrojové id pouijeme id uivatele a jako cílové id pouijeme id produktu. Nejprve pro kadou trojici urèíme pøíslušnı zdrojovı a cílovı blok. Toto je nutné z dùvodu urèení vazeb mezi všemi bloky. Pro kadou vstupní trojici tedy emitujeme klíè, dvojici hodnot obsahující identifikátory zdrojového a cíloveho bloku:

[source, scala, numbered]
----
include::{scala-dir}/mlonspark/ALSEngine.scala[tags=blockify-emit-key]
----  

Dále provedeme seskupovací operaci. Tato nam seskupí všechny hodnocení pro danou kombinaci zdrojového a cílového bloku. Vıstupem je tedy pøíslušnı klíè a kolekce odpovídajících hodnocení. Metoda RDD mapValues, nám dovolí transformovat pouze hodnoty (druhou poloku ze vstupní dvojice), vıstupem je tedy klíè ze vstupu spolu s novou hodnotou. Zde je vstupní hodnotou kolekce hodnocení kterou pøevedeme do pomocné struktry pro snaší manipulaci s daty bloku. Tato struktura je v takzvané COO (Coordinate Format) formì. Obsahuje tøi pole, kde hodnoty se stejnym indexem urcuji trojici zdrojoveho, ciloveho id a hodnoceni.:

[source, scala, numbered]
----
include::{scala-dir}/mlonspark/ALSEngine.scala[tags=blockify-coo]
----   

Z pole cilovych id pro dany zdrojovy a cilovy blok vybereme unikatni hodnoty, tyto seradime a priradime jim index urcujici jejich poradi. Hodnoty cilovych id namapujeme na odpovidajici index. Tyto indexy slouzi k propjeni cilovych a zdrojovych bloku viz. <<als_block_connection>>. Vzhledem k tomu ze vytvarime cilove bloky, transformujeme klic pouze na zdrojove id:

[source, scala, numbered]
----
include::{scala-dir}/mlonspark/ALSEngine.scala[tags=blockify-dstIdToLocalIndex]
---- 

V teto chvili mame ted RDD kde je klicem id zdrojoveho bloku a hodnotou blok hodnoceni. Pro jedno id zdrojoveho bloku muze byt v datasetu vice zaznamu, zhledem k tomu ze prislusny blok obsahuje hodnoceni pouze pro jeden cilovy blok. Dateset tedy seskupime dle klice, id zdrojoveho bloku. Jednotlive bloky hodnoceni spojime do jedineho bloku, obsahujiciho vsechny hodnoceni pro dany zdrojovy blok. Tento vysledny blok prevedeme do cilove formy tak jak je zobrazena v diagramu <<als_block_diagram>>. Dale na zaklade tohoto bloku vytvorime prislusny meta blok a blok faktoru, inicializovany na nahodne hodnoty.

Tento postup nasledne opakujeme, pouze s tim rozdilem, ze je jako zdrojove id pouzito id polozky a jako cilove id, id uzivatele. V teto chvili mame tedy vstupni data rozdeleny dio prislusnych bloku a pripravenych pro vypocty. 
