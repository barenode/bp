
==== Estimator

Hyper paramtery mají vliv na výsledné predikce hodnocení, jejich optimální hodnoty jsou závislé na datasetu, pro který vyváříme model. Přesné hodnoty odvodíme až při experimentování, typicky pomocí křížové validace <<CH ML>>. Algoritmus bude podporovat následující vstupní hyper parametry:

rank::
    Rank určuje dimenzi faktorových vektorů. Tato dimenze je vždy stejná jak pro uživatele tak i pro produkty. Pokud je velikost faktorových vektorů příliš nízký, model bude také příliš zjedndušený a nebudé podávat optimalní predikce. Na druhou stranu pokud bude tento počet příliš velký, může dojít k takzvanému přeučení, kdy model bude příliš spjatý s trénovacími daty. Výhozí hodnota je 10.
    
alpha::
    Alpha nastavuje poměr nárůstu důvěry v hodnocení, viz <<CH ALS>>. Výchozí hodnota je 0.1.
    
regParam::
    Regularizační parametr zabraňuje přeučení modelu. Hodnota 0 má za následek, že se při výpočtu regularizace neaplikuje. Výchozí hodnota je 0.1.  
    
Tréningové parametry nemají přímo vliv na nastavení výpočtu ale můžeme pomocí nich kontrolovat jak budou data distribuována v rámci výpočetního clustru. Data jsou před výpočtem samotným rozdělěna do bloků. Tyto bloky jsou vlastně partition a jsou následně zpracovávány paralelně. Zvolený počet bloků spoilu s kapacitou výpočetního clustru mají zásadní dopad na to, jak dlouho zabere vytvoření modelu. Dle <<HDG>> je optimalní velikost bloku mezi jedním až pěti miliony hodnocení. Náš algoritmus bude podporovat následující trénovací parametry:

numUserBlocks::
    Počet bloků do kterých budou rozděleni uživatelé, výchozí hodnota je 10. 

numItemBlocks::
    Počet bloků do kterých budou rozdělené produkty, výchozí hodnota je 10.
    
maxIter::
    Počet iterací při výpočtu. V každé iteraci se provede výpočet uživatelských a produktových faktorů. Po určitém počtu iterací se již výsledné faktory nemění a nemá smysl ve výpočtu pokračovat. Optimální počet iterací zjistíme například pomocí RMSE. Výchozí hodnota je 10.     

Další, pomocné parametry identifikují sloupce požadované pro výpočet v rámci vstupního datasetu:

userCol::
    Jméno sloupce ve vstupním datasetu, který obsahuje numerický identifikátor uživatele.

itemCol::
    Jméno sloupce ve vstupním datasetu, který obsahuje numerický identifikátor produktu. 

rating::
    Jméno sloupce ve vstupním datasetu, který obsahuje hodnocení. Hodnocení mohou nabývat reálných, nezáporných hodnot.
        
        
=====  Struktura bloků  

Pro práci s bloky zvolíme rozdílnou terminologii než rozdělení na uživatele a produkty. Vzhledem k povaze algoritmu, kdy se střídavě provádí výpočet faktorů zvlašť pro uživatele a zvlašť pro proukty, použijeme pro oba stejný algoritmus a vytvoříme pro ně analogické struktury. Jednou budou jako cíl výpočtu uživatelské faktory, které použijí jako zdroj pro výpočet faktory produktové. Podruhé to bude naopak. Dále tedy budeme pro vysvětlení algoritmu používat termíny zdroj a cíl. 

Pro vyhodnoceni ciloveho bloku vytvorime jednoduchou hashovaci funkci. Tato rozdeli hodnoceni rovnomerne dle zvoleneho celkove poctu bloku. Kazdemu uzivateli resp polozce prideli cilovy blok na zaklade jejich celociselneho identifikatoru. Vysleden cislo bloku bude take cele cislo v rade zacinajici nulou. Id bloku tedy take zaroven jeho indexem v sade prislusnych bloku. 

[[als_block_diagram]]
image::als_block_diagram02022020.jpg[title="Diagram bloku hodnoceni", pdfwidth="75%"]

V diagramu <<als_block_diagram>> je zobrazena struktura bloku hodncení. Pro každý blok vzniknou tři nezávislé struktury:

Blok::
    Základní struktura, obsahující příslušná hodnocení. Tyto bloky se inicializují na začátku výpočtu na základě vstupních dat. Data v nich zůstávají konstantní přes všechny iterace výpočtu. Výpočet se provádí lokálně na počítači kde jsou tyto data uložena, není tedy třeba tyto bloky v průbehu výpočtu opakovaně přenášet po síti v rámci výpočetního clustru. V těchto blocích je jeden z identifikátorů zvolen jak zdrojový a druhý jako cílový. Hodnocení jsou seřazena dle zdrojového identifikátoru (vzestupně). Data v bloku jsou  zkomprimována do takzvané CSC (compressed sparse column) struktury. Vzhledem k tomu, že jeden zdrojový identifikátor může být v datech zastoupený několikrát, vybereme nejprve unikátní zdrojové identifikátory viz. (Zdrojové ID) <<als_block_diagram>>. K těmto identifikátorům přiřadíme ukazatel do bloku hodnocení. Tento ukazatel určuje ke kterým hodnocením příslušné zdrojové ID patří. Cílový identifikátor nahradíme v datech identifikátorem cílového bloku a lokálním indexem. Lokální index určuje index seřazených unikatních cílových id pro dany zdrojový a cílový blok. Tyto idenitifikátory provazují zdrojový blok a cílový meta blok.
    
Blok faktorů::
    Pro každé unikátní zdrojové id v rámci propojeného bloku bude v tomto bloku právě jeden faktorový vektor. Dimenze těchto vektorů je dána zvoleným rankem, typicky se jedná o relativně nízkou hodnotu, viz. výchozí hodnota 10. Tyto faktory se přepočítávají v rámci každé iterace a jsou následně použity jako zdroj pro výpočet cílových faktorů. Tyto bloky je tedy nutné v průběhu výpočtu distribuovat v rámci clustru. Blok faktorů inicializujeme na začátku výpočtu a jednotlivým faktorům přiřadíme náhodná reálná čísla.
    
Meta blok::
    Na základě dat v bloku vytvoříme takzvaný metablok. Metabloky mezi sebou provazují zdrojové a cílové bloky. Reálně se jedná o dvourozměrné pole kde je záznam pro každý cílový blok. V těchto záznamech jsou zdrojová id, pro které existuje hodnocení v daném zdrojovém a cílovém bloku. 
       
[[als_block_connection]]
image::als_block_connection02022020.jpg[title="Diagram propojeni bloku", pdfwidth="75%"]

V diagramu <<als_block_connection>> je zobrazené propojené mezi zdrojovými a cílovými bloky. Pokud chceme spočítat zdrojový faktor pro jedno zdrojové id (30)musíme do lineárního systému zahrnout včechny cílové faktory (cílové id 5, 12) pro které existuje hodnocení pro dané zdrojové a cílové id. Tyto mohou být typicky v rozdílných cílových blocích (1, 4) uložených na rozdílných počítačích v rámci clustru.


=====  Rozdělení hodnoceni do bloků 

Jako top level vstup do algoritmu použijeme strukturované API jako preferovaný způsob od druhé generace Sparku. Dataset musí obsahovat sloupce identifikované vstupními parametry userCol, itemCol a rating. V rámci algoritmu samotného ale pro práci s hodnoceními použijeme RDD API. Toto API nižší úrovně nám, narozdíl od doporučovaného, strukturovaného API, dává možnost řídit rozložení dat v rámci clustru. Jako vstup do části algoritmu, který nám rozdělí hodnocení do příslušných bloků, nejprve převedeme vstupní dataset do RDD uspořádaných trojic:

[source, scala, numbered]
----
include::{scala-dir}/mlonspark/AlternatingLeastSquare.scala[tags=dataset-to-rdd]
----

Tato trojice se skládá ze zdrojového id (srcId), ciloveho id (dstId) a hodnocení. Nejprve vytvoříme uživatelské bloky, tj. jako zdrojové id použijeme id uživatele a jako cílové id použijeme id produktu. Nejprve pro každou trojici určíme příslušný zdrojový a cílový blok. Toto je nutné z důvodu určení vazeb mezi všemi bloky. Pro každou vstupní trojici tedy emitujeme klíč, dvojici hodnot obsahující identifikátory zdrojového a cíloveho bloku:

[source, scala, numbered]
----
include::{scala-dir}/mlonspark/ALSEngine.scala[tags=blockify-emit-key]
----  

Dále provedeme seskupovací operaci. Tato nam seskupí všechny hodnocení pro danou kombinaci zdrojového a cílového bloku. Výstupem je tedy příslušný klíč a kolekce odpovídajících hodnocení. Metoda RDD mapValues, nám dovolí transformovat pouze hodnoty (druhou položku ze vstupní dvojice), výstupem je tedy klíč ze vstupu spolu s novou hodnotou. Zde je vstupní hodnotou kolekce hodnocení kterou převedeme do pomocné struktry pro snažší manipulaci s daty bloku. Tato struktura je v takzvané COO (Coordinate Format) formě. Obsahuje tři pole, kde hodnoty se stejným indexem určují trojici zdrojového resp. cílového id a příslušného hodnocení:

[source, scala, numbered]
----
include::{scala-dir}/mlonspark/ALSEngine.scala[tags=blockify-coo]
----   

Z pole cílových id pro daný zdrojový a cílový blok vybereme unikátní hodnoty, tyto seřadíme a přiřadíme jim index určujíci jejich pořadí. Hodnoty cílových id namapujeme na odpovidající index. Tyto indexy slouží k propojení cílových a zdrojových bloků viz. <<als_block_connection>>. Vzhledem k tomu, že vytváříme cílové bloky, transformujeme klíč pouze na zdrojové id:

[source, scala, numbered]
----
include::{scala-dir}/mlonspark/ALSEngine.scala[tags=blockify-dstIdToLocalIndex]
---- 

V této chvíli máme tedy RDD kde je klíčem id zdrojového bloku a hodnotou blok hodnocení. Pro jedno id zdrojového bloku může být v datasetu více záznamů, zhledem k tomu, že příslušný blok obsahuje hodnocení pouze pro jediný cílový blok. Dateset tedy seskupíme dle klíče, id zdrojového bloku. Jednotlive bloky hodnocení spojíme do jediného bloku, obsahujícího všechny hodnocení pro daný zdrojový blok. Tento výsledný blok převedeme do cílové formy tak jak je zobrazena v diagramu <<als_block_diagram>>. Dále na základě tohoto bloku vytvoříme příslušný meta blok a blok faktorů, inicializovaný na náhodné hodnoty.

Tento postup následně opakujeme, pouze s tím rozdílem, že je jako zdrojové id použito id produktu a jako cílove id, id uživatele. V této chvíli máme tedy vstupní data rozdělena do příslušných bloků, připravených pro výpočet samotný. 
