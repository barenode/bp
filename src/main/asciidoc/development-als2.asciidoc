
==== Estimator

Hyper paramtery mají vliv na výsledné predikce hodnocení, jejich optimální hodnoty jsou závislé na datasetu, pro který vyváøíme model. Pøesné hodnoty odvodíme až pøi experimentování, typicky pomocí køížové validace <<CH ML>>. Algoritmus bude podporovat následující vstupní hyper parametry:

rank::
    Rank urèuje dimenzi faktorových vektorù. Tato dimenze je vždy stejná jak pro uživatele tak i pro produkty. Pokud je velikost faktorových vektorù pøíliš nízký, model bude také pøíliš zjedndušený a nebudé podávat optimalní predikce. Na druhou stranu pokud bude tento poèet pøíliš velký, mùže dojít k takzvanému pøeuèení, kdy model bude pøíliš spjatý s trénovacími daty. Výhozí hodnota je 10.
    
alpha::
    Alpha nastavuje pomìr nárùstu dùvìry v hodnocení, viz <<CH ALS>>. Výchozí hodnota je 0.1.
    
regParam::
    Regularizaèní parametr zabraòuje pøeuèení modelu. Hodnota 0 má za následek, že se pøi výpoètu regularizace neaplikuje. Výchozí hodnota je 0.1.  
    
Tréningové parametry nemají pøímo vliv na nastavení výpoètu ale mùžeme pomocí nich kontrolovat jak budou data distribuována v rámci výpoèetního clustru. Data jsou pøed výpoètem samotným rozdìlìna do blokù. Tyto bloky jsou vlastnì partition a jsou následnì zpracovávány paralelnì. Zvolený poèet blokù spoilu s kapacitou výpoèetního clustru mají zásadní dopad na to, jak dlouho zabere vytvoøení modelu. Dle <<HDG>> je optimalní velikost bloku mezi jedním až pìti miliony hodnocení. Náš algoritmus bude podporovat následující trénovací parametry:

numUserBlocks::
    Poèet blokù do kterých budou rozdìleni uživatelé, výchozí hodnota je 10. 

numItemBlocks::
    Poèet blokù do kterých budou rozdìlené produkty, výchozí hodnota je 10.
    
maxIter::
    Poèet iterací pøi výpoètu. V každé iteraci se provede výpoèet uživatelských a produktových faktorù. Po urèitém poètu iterací se již výsledné faktory nemìní a nemá smysl ve výpoètu pokraèovat. Optimální poèet iterací zjistíme napøíklad pomocí RMSE. Výchozí hodnota je 10.     

Pomocne parametry identifikuji pozadovane sloupce v ramci vstupniho datasetu.

userCol::
    Jmeno sloupce ve vstupnim datasettu, ktery obsahuje identifikator uzivatele. Vsechny hodnoty v danem slopci by mely byt cele cislo.

itemCol::
    Jmeno sloupce ve vstupnim datasettu, ktery obsahuje identifikator polozky. Vsechny hodnoty v danem slopci by mely byt cele cislo.

rating::
    Jmeno sloupce ve vstupnim datasettu, ktery obsahuje hodnoceni. Hodnoceni mohou nabyvat realnych, nezapornych hodnot.
        
Hodnoceni nejprve rozdelime do jednotlivych bloku.  

Pro praci s bloky zvolime rozdilnou terminologii nez rozdelenmi na uzivatele a polozky. Vzhledem k povaze algoritmu, kdy se stridave porvadi vypocet faktoru zvlast pro uzvatele a zvlast pro polozky, pouzijeme pro oba stejny algoritmus a vytvorime pro ne analogicke struktury. Jednou budou jako cil vypoctu uzivatelske faktory, ktere pouziji jako zdroj pro vypocet faktory polkozkove. Podruhe to bude naopak. Dale tedy budeme pro vysvetleni algoritmu pouzivat terminy zdroj a cil. 

Pro vyhodnoceni ciloveho bloku vytvorime jednoduchou hashovaci funkci. Tato rozdeli hodnoceni rovnomerne dle zvoleneho celkove poctu bloku. Kazdemu uzivateli resp polozce prideli cilovy blok na zaklade jejich celociselneho identifikatoru. Vysleden cislo bloku bude take cele cislo v rade zacinajici nulou. Id bloku tedy take zaroven jeho indexem v sade prislusnych bloku. 

[[als_block_diagram]]
image::als_block_diagram02022020.jpg[title="Diagram bloku hodnoceni", pdfwidth="75%"]


V diagramu je <<als_block_diagram>> je ukazana struktura bloku. Pro kazdy blok hodnceni vzniknou tri nezavisle struktury:

Blok::
    Zakladni struktura, obsahujici prislusna hodnoceni. Tyto bloky se inicializuji na zacatku vypoctu na zaklade vstupnich dat. Data v nich zustavaji konstantni pres vsechny iterace vypoctu. Vypocet se provadi lokalne na uzlu kde jsou tyto data ulozena, neni tedy potreba tyto bloky v prubehu vypoctu prenaset po siti v ramci vypocetniho clustru. V techto blocich je jeden z identifikatoru zvolen jak zdrojovy a druhy jako cilovy. Hodnoceni jsou nasledne serazena dle zdrojoveho identifikatoru (vzestupne). Data v bloku zkomprimuje do takzvane CSC (compressed sparse column) struktury. Vzheledem k tomu, ze jeden zdrojovy identifikator muze byt v datech zastoupeny nekolikrat, vybereme nejprve unikatni zdrojove identifikatory viz (Zdrojove ID) <<als_block_diagram>>. K temto identifikatorum priradime ukazatel do bloku hodnoceni. Tento ukazatel urcuje ke kterym hodnocenim prislusne zdrojove ID patri. Cilovy identifikator nahradime v datech identifikatorem ciloveho bloku a tazkvanym lokalnim indexem. Localni index urcuje index serazenych unikatnich cilovych id pro dany zdrojovy a cilovy blok. Tyto idenitifikatory provazuji zdrojovy blok a cilovy meta blok.
    
Blok faktoru::
    Pro kazde unikatni zdrojove id v ramci propojeneho bloku bude v tomto bloku prave jeden faktorovy vektor. Dimenze techto vektoru je dana zvolenym rankem, typicky se jedna o relativne male cislo, viz vychozi hodnota 10. Tyto faktory se prepocitaji v ramci kazde iterace a jsou nasledne pouzity jako zdroj pro vypocet cilovych faktoru. Tyto bloky bude tedy nutne v prubehu distribuovaty jako zdroj. Blok faktoru inicializujeme na zacatku vypoctu a jednotlivym faktorum priradime nahodne hodnoty.
    
Meta blok::
    Na zaklade dat v bloku vytvorime takzvany metablok. Metabloky provazuji mezi sebou zdrojove a cilove bloky. Realne se jedna o dvourozmerne pole kde je zaznam pro kazdy cilovy blok. V techto zaznamech jsou zdrojova id, pro ktere existuje  hodnoceni v danem zdrojovem a cilovem bloku. 
       
[[als_block_connection]]
image::als_block_connection02022020.jpg[title="Diagram propojeni bloku", pdfwidth="75%"]


Na obrazku <<als_block_connection>> je zobrazene propojeni mezi zdrojovymi a cilovymi bloky. POkud chceme spocitat zdrojovy faktor pro jedno zdrojove id (30)musime do linearniho systemu zahrnou vsechny cilove faktory (cilove id 5, 12) pro ktere existuje hodnoceni pro dane zdrojove a cilove id. Tyto mohou byt typicky v rozdilnych cilovych blocich (1, 4) ulozenych na rozdilnych uzlech v ramci clustru.


Jako top level vstup do algoritmu pouzijeme strukturovane API jako preferrovany zpusob od druhe generace Sparku. Dataset muzi obsahovat slupce identifikovane vstpnumi parametry userCol, itemCol a rating. V ramci algoritmu samotneho ale praci s hodnocenimi pouzijeme RDD Api. Toto api nizsi urovne nam, narozdil od doporucovaneho strukturovaneho API, dava moznost ridit rozlozeni dat v ramci clusteru. Jako vstup do casti algoritmu, ktery nam rozdeli hodnoceni do prislusnych bloku, nejprve prevedeme vstupni dataset do RDD usporadanych trojic:

[source, scala, numbered]
----
include::{scala-dir}/mlonspark/AlternatingLeastSquare.scala[tags=dataset-to-rdd]
----

Tato trojice se sklada ze sdrojoveh id (srcId), ciloveho id (dstId) a hodnoceni. 
Nejprve vytvorime uzivatelske bloky, tj. jako zdrojove id pouzijeme id uzivatele a jako cilove id pouzijeme id polozky. Nejprve pro kazdou trojici urcime prislusny zdrojovy a cilovy blok. Toto je nutne z duvodu urceni vazeb mezi vsemi  bloky. Pro kazdou vstupni trojici tedy emitujeme klic, dvojici hodnot, identifikatory zdrojoveho a ciloveho bloku:

[source, scala, numbered]
----
include::{scala-dir}/mlonspark/ALSEngine.scala[tags=blockify-emit-key]
----  

Dale provedeme seskupovaci operaci. Tato nam seskupi vsechny hodnoceni pro danou kombinaci zdrojoveho a ciloveho bloku. Vystupem je tedy prislusny klic a kolekce odpovidajicich hodnoceni. Metoda mapValues, nam dovoli transformovat pouze hodnoty (druhou polozku ze vstupni dvojice), vystupem je tedy klic ze vstupu spolu s novou hodnotou. Zde je vstupni hodnotou kolekce hodnoceni kteru si prevedeme do pomocne struktry pro snazsi manipulaci s daty bloku. Tato struktura je v takzvane COO (Coordinate Format) forme. Obsahuje tri pole, kde hodnoty se stejnym indexem urcuji trojici zdrojoveho, ciloveho id a hodnoceni.:

[source, scala, numbered]
----
include::{scala-dir}/mlonspark/ALSEngine.scala[tags=blockify-coo]
----   

Z pole cilovych id pro dany zdrojovy a cilovy blok vybereme unikatni hodnoty, tyto seradime a priradime jim index urcujici jejich poradi. Hodnoty cilovych id namapujeme na odpovidajici index. Tyto indexy slouzi k propjeni cilovych a zdrojovych bloku viz. <<als_block_connection>>. Vzhledem k tomu ze vytvarime cilove bloky, transformujeme klic pouze na zdrojove id:

[source, scala, numbered]
----
include::{scala-dir}/mlonspark/ALSEngine.scala[tags=blockify-dstIdToLocalIndex]
---- 

V teto chvili mame ted RDD kde je klicem id zdrojoveho bloku a hodnotou blok hodnoceni. Pro jedno id zdrojoveho bloku muze byt v datasetu vice zaznamu, zhledem k tomu ze prislusny blok obsahuje hodnoceni pouze pro jeden cilovy blok. Dateset tedy seskupime dle klice, id zdrojoveho bloku. Jednotlive bloky hodnoceni spojime do jedineho bloku, obsahujiciho vsechny hodnoceni pro dany zdrojovy blok. Tento vysledny blok prevedeme do cilove formy tak jak je zobrazena v diagramu <<als_block_diagram>>. Dale na zaklade tohoto bloku vytvorime prislusny meta blok a blok faktoru, inicializovany na nahodne hodnoty.

Tento postup nasledne opakujeme, pouze s tim rozdilem, ze je jako zdrojove id pouzito id polozky a jako cilove id, id uzivatele. V teto chvili mame tedy vstupni data rozdeleny dio prislusnych bloku a pripravenych pro vypocty. 
