
=== Alternating Least Square (ALS)

Algoritmus se sklada ze dvou hlavnich komponent. Tyto komponenty pouzivaji standartni nastroje strandartni knihovny Spark MLlib.     

Hyper paramtery maji vliv na vysledne hodnoty, jejich optimalni hodnoty jsou zavisle na datasetu, pro ktery vyvarime model. Presne hodnoty odvodime pri experimentovani pomoci krizove validace. NAs Algoritmus bude podporovat nasledujici vstupni hyper parametry:

rank::
    Rank urcuje dimenzi faktorovych vektoru. Tato dimenze je stejna jak pro uzivatele tak i pro polozky. Pokud je velikost faktorovych veektoru prilis nizka, model bude prilis zjednduseny a nebude podavat optimalni vykon. Na druhou stranu pokud bude jejich velikost prilis velka, muze dojit k takzvanemu preuceni kdy model bude prilis spjaty s trenovacimi daty. Vyhozi hodnota je 10.
    
alpha::
    Alpha nastavuje pomer narustu duvery v hodnoceni, viz <<ALS>>. Vychozi hodnota je 0.1.
    
regParam::
    Regularizacni parametr zabranuje preuceni modelu, viz <<REGULARIZATION>>. Hodnota 0 ma za nasledek, ze se pri vypoctu regulaizace neaplikuje. Vychopzi hodnota je 0.1.  
    
Trenovaci parametry nemaji primo vliv na nastaveni vypoctu ale muzeme pomoci nich kontrolovat jak budou data distribuovana v ramci vypocetniho klusteru. Data jsou pred vypoctem samotnym rozdeleny do bloku. Tyto bloky jsou vlastne partition a jsou nasledne zpracovavany parallelne. Zvoleny pocet bloku ma zasadni dopad na to, jak dlouho zabere vytvoreni modelu. Dle <<HDG>> je optimalni velikost bloku mezi jednim az peti miliony hodnoceni. Nas algoritmus bude podporovat nasledujici trenovaci parametry:

numUserBlocks::
    POcet bloku do kterych budou rozdeleleni uzivatele, vychozi hodnota je 10. 

numItemBlocks::
    POcet bloku do kterych budou rozdelelene polozky, vychozi hodnota je 10.
    
maxIter::
    POcet iteraci pri vypoctu. V kazde iteraci se provede vypocet uzivatelskych a polozkovych faktoru. Po danem poctu iteraci se jiz vysledne faktory nemeni a nema smysl ve vypoctu pokracovat. Presny pocet zjistime napriklad pomoci RMSE. Vychozi hodnota je 10.     

Pomocne parametry identifikuji pozadovane sloupce v ramci vstupniho datasetu.

userCol::
    Jmeno sloupce ve vstupnim datasettu, ktery obsahuje identifikator uzivatele. Vsechny hodnoty v danem slopci by mely byt cele cislo.

itemCol::
    Jmeno sloupce ve vstupnim datasettu, ktery obsahuje identifikator polozky. Vsechny hodnoty v danem slopci by mely byt cele cislo.

rating::
    Jmeno sloupce ve vstupnim datasettu, ktery obsahuje hodnoceni. Hodnoceni mohou nabyvat realnych, nezapornych hodnot.
        
Hodnoceni nejprve rozdelime do jednotlivych bloku.  

Pro praci s bloky zvolime rozdilnou terminologii nez rozdelenmi na uzivatele a polozky. Vzhledem k povaze algoritmu, kdy se stridave porvadi vypocet faktoru zvlast pro uzvatele a zvlast pro polozky, pouzijeme pro oba stejny algoritmus a vytvorime pro ne analogicke struktury. Jednou budou jako cil vypoctu uzivatelske faktory, ktere pouziji jako zdroj pro vypocet faktory polkozkove. Podruhe to bude naopak. Dale tedy budeme pro vysvetleni algoritmu pouzivat terminy zdroj a cil. 

Pro vyhodnoceni ciloveho bloku vytvorime jednoduchou hashovaci funkci. Tato rozdeli hodnoceni rovnomerne dle zvoleneho celkove poctu bloku. Kazdemu uzivateli resp polozce prideli cilovy blok na zaklade jejich celociselneho identifikatoru. Vysleden cislo bloku bude take cele cislo v rade zacinajici nulou. Id bloku tedy take zaroven jeho indexem v sade prislusnych bloku. 

[[als_block_diagram]]
image::als_block_diagram02022020.jpg[title="Diagram bloku hodnoceni", pdfwidth="75%"]


V diagramu je <<als_block_diagram>> je ukazana struktura bloku. Pro kazdy blok hodnceni vzniknou tri nezavisle struktury:

Blok::
    Zakladni struktura, obsahujici prislusna hodnoceni. Tyto bloky se inicializuji na zacatku vypoctu na zaklade vstupnich dat. Data v nich zustavaji konstantni pres vsechny iterace vypoctu. Vypocet se provadi lokalne na uzlu kde jsou tyto data ulozena, neni tedy potreba tyto bloky v prubehu vypoctu prenaset po siti v ramci vypocetniho clustru. V techto blocich je jeden z identifikatoru zvolen jak zdrojovy a druhy jako cilovy. Hodnoceni jsou nasledne serazena dle zdrojoveho identifikatoru (vzestupne). Data v bloku zkomprimuje do takzvane CSC (compressed sparse column) struktury. Vzheledem k tomu, ze jeden zdrojovy identifikator muze byt v datech zastoupeny nekolikrat, vybereme nejprve unikatni zdrojove identifikatory viz (Zdrojove ID) <<als_block_diagram>>. K temto identifikatorum priradime ukazatel do bloku hodnoceni. Tento ukazatel urcuje ke kterym hodnocenim prislusne zdrojove ID patri. Cilovy identifikator nahradime v datech identifikatorem ciloveho bloku a tazkvanym lokalnim indexem. Localni index urcuje index serazenych unikatnich cilovych id pro dany zdrojovy a cilovy blok. Tyto idenitifikatory provazuji zdrojovy blok a cilovy meta blok.
    
Blok faktoru::
    Pro kazde unikatni zdrojove id v ramci propojeneho bloku bude v tomto bloku prave jeden faktorovy vektor. Dimenze techto vektoru je dana zvolenym rankem, typicky se jedna o relativne male cislo, viz vychozi hodnota 10. Tyto faktory se prepocitaji v ramci kazde iterace a jsou nasledne pouzity jako zdroj pro vypocet cilovych faktoru. Tyto bloky bude tedy nutne v prubehu distribuovaty jako zdroj. Blok faktoru inicializujeme na zacatku vypoctu a jednotlivym faktorum priradime nahodne hodnoty.
    
Meta blok::
    Na zaklade dat v bloku vytvorime takzvany metablok. Metabloky provazuji mezi sebou zdrojove a cilove bloky. Realne se jedna o dvourozmerne pole kde je zaznam pro kazdy cilovy blok. V techto zaznamech jsou zdrojova id, pro ktere existuje  hodnoceni v danem zdrojovem a cilovem bloku. 
       
[[als_block_connection]]
image::als_block_connection02022020.jpg[title="Diagram propojeni bloku", pdfwidth="75%"]


Na obrazku <<als_block_connection>> je zobrazene propojeni mezi zdrojovymi a cilovymi bloky. POkud chceme spocitat zdrojovy faktor pro jedno zdrojove id (30)musime do linearniho systemu zahrnou vsechny cilove faktory (cilove id 5, 12) pro ktere existuje hodnoceni pro dane zdrojove a cilove id. Tyto mohou byt typicky v rozdilnych cilovych blocich (1, 4) ulozenych na rozdilnych uzlech v ramci clustru.


Jako top level vstup do algoritmu pouzijeme strukturovane API jako preferrovany zpusob od druhe generace Sparku. Dataset muzi obsahovat slupce identifikovane vstpnumi parametry userCol, itemCol a rating. V ramci algoritmu samotneho ale praci s hodnocenimi pouzijeme RDD Api. Toto api nizsi urovne nam, narozdil od doporucovaneho strukturovaneho API, dava moznost ridit rozlozeni dat v ramci clusteru. Jako vstup do casti algoritmu, ktery nam rozdeli hodnoceni do prislusnych bloku, nejprve prevedeme vstupni dataset do RDD usporadanych trojic:

[source, scala, numbered]
----
include::{scala-dir}/mlonspark/AlternatingLeastSquare.scala[tags=dataset-to-rdd]
----

Tato trojice se sklada ze sdrojoveh id (srcId), ciloveho id (dstId) a hodnoceni. 
Nejprve vytvorime uzivatelske bloky, tj. jako zdrojove id pouzijeme id uzivatele a jako cilove id pouzijeme id polozky. Nejprve pro kazdou trojici urcime prislusny zdrojovy a cilovy blok. Toto je nutne z duvodu urceni vazeb mezi vsemi  bloky. Pro kazdou vstupni trojici tedy emitujeme klic, dvojici hodnot, identifikatory zdrojoveho a ciloveho bloku:

[source, scala, numbered]
----
include::{scala-dir}/mlonspark/ALSEngine.scala[tags=blockify-emit-key]
----  

Dale provedeme seskupovaci operaci. Tato nam seskupi vsechny hodnoceni pro danou kombinaci zdrojoveho a ciloveho bloku. Vystupem je tedy prislusny klic a kolekce odpovidajicich hodnoceni. Metoda mapValues, nam dovoli transformovat pouze hodnoty (druhou polozku ze vstupni dvojice), vystupem je tedy klic ze vstupu spolu s novou hodnotou. Zde je vstupni hodnotou kolekce hodnoceni kteru si prevedeme do pomocne struktry pro snazsi manipulaci s daty bloku. Tato struktura je v takzvane COO (Coordinate Format) forme. Obsahuje tri pole, kde hodnoty se stejnym indexem urcuji trojici zdrojoveho, ciloveho id a hodnoceni.:

[source, scala, numbered]
----
include::{scala-dir}/mlonspark/ALSEngine.scala[tags=blockify-coo]
----   

Z pole cilovych id pro dany zdrojovy a cilovy blok vybereme unikatni hodnoty, tyto seradime a priradime jim index urcujici jejich poradi. Hodnoty cilovych id namapujeme na odpovidajici index. Tyto indexy slouzi k propjeni cilovych a zdrojovych bloku viz. <<als_block_connection>>. Vzhledem k tomu ze vytvarime cilove bloky, transformujeme klic pouze na zdrojove id:

[source, scala, numbered]
----
include::{scala-dir}/mlonspark/ALSEngine.scala[tags=blockify-dstIdToLocalIndex]
---- 

V teto chvili mame ted RDD kde je klicem id zdrojoveho bloku a hodnotou blok hodnoceni. Pro jedno id zdrojoveho bloku muze byt v datasetu vice zaznamu, zhledem k tomu ze prislusny blok obsahuje hodnoceni pouze pro jeden cilovy blok. Dateset tedy seskupime dle klice, id zdrojoveho bloku. Jednotlive bloky hodnoceni spojime do jedineho bloku, obsahujiciho vsechny hodnoceni pro dany zdrojovy blok. Tento vysledny blok prevedeme do cilove formy tak jak je zobrazena v diagramu <<als_block_diagram>>. Dale na zaklade tohoto bloku vytvorime prislusny meta blok a blok faktoru, inicializovany na nahodne hodnoty.

Tento postup nasledne opakujeme, pouze s tim rozdilem, ze je jako zdrojove id pouzito id polozky a jako cilove id, id uzivatele. V teto chvili mame tedy vstupni data rozdeleny dio prislusnych bloku a pripravenych pro vypocty. 
