== Závěr

Apache Spark je užitečný nástroj s jednoduchým a srozumitelným API. Komplexní, distribuovaný algoritmus pro strojové učení se na této platformě podařilo implementovat i bez předchozích zkušeností. Apache Spark má kvalitní dokumentaci a širokou vývojářskou základnu. Tyto dva prvky výrazně usnadňovaly řešení problemů v průběhu implementace. V projektu byl použit programovací jazyk Scala, nativní jazyk Sparku. Ačkoliv se pro Java vývojáře mohla zdát syntaxe Scaly poněkud složitá, během implementace projektu vynikla síla tohoto jazyka. Zejména podpora funkcionálního programování činí z tohoto jazyka ideální volbu pro Spark. Integrované vývojové prostředí IntelliJ IDEA se ukázalo jako správná volba. Kvalitní podpora programovaciho jazyka Scala a jednotkových testů umožnila efektivní vývoj a rychlé testování aplikace.  
  
Apache Hadoop ma pozvolnou křivku učení. Porozumět účelu jednotlivých částí systému potřebných pro běh Spark aplikace a poskládat tyto části do funkčního celku se ukázalo jako časové náročný proces. Při spoustění aplikace docházelo zprvu k haváriím, které si vyžádaly prověřování specifických systémových logů a následnou rekonfiguraci problematických prvků.  
 
Pro aplikaci vyvinutého algoritmu na konkrétní dataset byl použit programovací jazyk Python v rámci interaktivních zápisníků Jupyter. Tato kombinace se ukázala jako praktický nástroj pro ladění jednotlivých hyper parametrů a vizualizaci výsledků. 

Velkým překvapením je algoritmus ALS. Doporučení sestavená na základě tohoto algoritmu se ukázala jako velice kvalitní. Také nalezení optimálních hodnot pro jednotlivé hyper parametry mělo za následek zvýšení přesnosti modelu i kvalitativní posun výsledných doporučení.  

Závěrem lze konstatovat, že na zvolených technologiích je možné realizovat systém pro produkční použití. Takový systém, odolný vůči softwarovým i hardwarovým haváriím, by bylo možné škálovat pro milióny zákazníků a desítky tisíc produktů.




     